# Texas Greenbook 15th Edition CSL Development TODO

## Legend & Status Conventions
- [x] Completed item.
- [ ] Outstanding item awaiting work.
- Nested checklists enumerate the full subtask inventory required to complete each parent entry, so clearing a parent task requ
ires checking off every indented child.

## Completed Work
- [x] **Familiarized with source material.** Cataloged rule coverage, appendices, and page citations from the Greenbook PDF and logged them in `NOTES.md` for traceability.
  - [x] Read the entire Greenbook PDF, bookmarking chapters with unresolved CSL implications for later reference.
  - [x] Indexed each citation rule with page and section numbers inside `NOTES.md`, using consistent anchors for cross-linking.
  - [x] Captured appendix abbreviations and tables in a structured outline to inform locale and macro design decisions.
  - [x] Flagged ambiguous or conflicting guidance in `NOTES.md` with follow-up questions for future research tasks.
- [x] **Surveyed existing CSL styles.** Reviewed Bluebook-derived and legal-dependent templates, noting reusable macros and locale patterns in `NOTES.md`.
  - [x] Audited representative legal CSL styles (e.g., Bluebook, ALWD) to assess reusable macro patterns.
  - [x] Documented locale overrides and jurisdiction handling strategies that could translate to the Greenbook effort.
  - [x] Logged promising helper macros and structural motifs in `NOTES.md`, including file paths for quick lookup.
  - [x] Identified gaps in existing styles that necessitated bespoke Texas-specific implementations.
- [x] **Defined citation requirements.** Produced the citation requirement matrix with mandatory variables, abbreviations, and Greenbook page references.
  - [x] Compiled authority categories (cases, statutes, regulations, secondary sources) with required CSL variables.
  - [x] Cross-referenced each requirement with the corresponding Greenbook rule citations.
  - [x] Added abbreviation guidance from Appendix A into the matrix to drive locale planning.
  - [x] Validated the matrix against sample citations to ensure metadata coverage was sufficient.
- [x] **Designed style architecture.** Established the macro routing now preserved in `texas-greenbook-15th-edition.csl` and its Table of Authorities variants.
  - [x] Drafted macro dependency diagrams outlining note, bibliography, and TOA entry points.
  - [x] Segmented authority handling into reusable helpers to minimize duplication between style variants.
  - [x] Verified that macro names and scopes conform to CSL schema conventions.
  - [x] Recorded architectural rationale and known trade-offs in `NOTES.md` for reviewer transparency.
- [x] **Drafted primary CSL files.** Authored legacy drafts (`draft0`–`draft3`, now archived) along with TOA counterparts covering primary authorities.
  - [x] Iteratively produced draft styles capturing incremental rule coverage milestones.
  - [x] Archived superseded drafts under `temp/archive/` with descriptive filenames for historical traceability.
  - [x] Maintained synchronization between note and TOA variants during each drafting round.
  - [x] Documented milestone achievements and remaining gaps at the end of each draft cycle.
- [x] **Implemented secondary source rules.** Completed book-, journal-, CLE-, and web-specific macros shared between citation and bibliography outputs.
  - [x] Cataloged secondary source authority types with Greenbook references prior to implementation.
  - [x] Built shared macros for contributors, pinpoint references, and access dates usable across multiple item types.
  - [x] Validated outputs against Greenbook examples and captured deviations in `NOTES.md`.
  - [x] Synced TOA handling for secondary materials where applicable or documented exclusions.
- [x] **Created regression fixtures.** Added `tests.json`, `tests_toa.json`, and matching `expected*.txt` files for authorities and TOA scenarios.
  - [x] Authored representative citeproc JSON entries for each authority class covered by the drafts.
  - [x] Generated baseline expected outputs using the current CSL implementations.
  - [x] Stored fixture provenance (rule citations, assumptions) directly in `NOTES.md` for auditability.
  - [x] Organized fixtures into logical groupings (general, secondary, TOA) to streamline targeted testing.
- [x] **Prepared working documentation.** Wrote the `README.md` overview, expanded research `NOTES.md`, and tracked assumptions and deviations.
  - [x] Summarized repository contents and workflow expectations in `temp/README.md`.
  - [x] Populated `NOTES.md` with research findings, open questions, and design decisions linked to Greenbook citations.
  - [x] Established `TODO.md` as the living backlog, aligning entries with documentation anchors.
  - [x] Reviewed documents for consistency and clarity before marking the preparation complete.

## Active Development
### Citation Logic Gaps
- [ ] **Complete statute and rule short-form logic.** Implement cross-reference and `Id.` handling for statutes, rules, and administrative materials, then update `expected.txt` fixtures. (See `README.md` Known Limitations and `NOTES.md` helper sketches.)
  - [ ] Audit the existing statute, rule, and administrative `*_short` macros in `texas-greenbook-15th-edition.csl` to catalog current branching and pinpoint missing reuse hooks documented in `NOTES.md`.
    - [ ] Locate all `*_short` macros in both the primary style and TOA variants using the CSL editor or `rg` searches.
      - [x] Run `rg "_short" temp -n` to generate an initial list of macro definitions and invocations. (Confirmed command currently only surfaces backlog references because implemented macros are hyphenated; noted follow-up in `NOTES.md`.)
      - [x] Open `texas-greenbook-15th-edition.csl` and TOA counterparts in a CSL-aware editor to confirm the matches and capture surrounding context. (Verified short-form coverage for cases/secondary materials and documented absence in TOA variants.)
      - [x] Copy the macro names and file locations into `NOTES.md`, grouping them by authority type for easy reference. (Inventory logged under “Short-form macro inventory (2025-11-02)”.)
      - [x] Flag any macros with ambiguous naming or duplicate purposes for follow-up clarification tasks.
        - [x] Review each inventoried macro name against its implementation to confirm the intended scope and avoid overlaps.
        - [x] Document ambiguous or duplicated macros in `NOTES.md`, including file names, line ranges, and a concise descript
ion of the conflicting behavior.
        - [x] Draft proposed resolutions (rename, consolidate, or split) and record the rationale alongside related requirement
 matrix entries.
        - [x] Create follow-up TODO entries or GitHub issues for any macros that require broader refactors or reviewer input. (2025-11-02 review confirmed existing backlog coverage; no new entries required beyond the standing short-form epic noted in `NOTES.md`.)
    - [x] Diagram current conditional logic and data dependencies for each macro in `NOTES.md` to identify overlapping pathways.
      - [x] For every macro captured, sketch the `if/else` and `choose` structures, noting required variables and fallback behavior.
      - [x] Highlight reuse of helper macros or localized terms to map dependency chains accurately.
      - [x] Record gaps where inputs are assumed but not enforced, marking them for later validation tooling.
      - [x] Include references to relevant lines or sections within the CSL files so diagrams can be quickly cross-checked.
    - [x] Compare macro inputs/outputs with the requirement matrix to spot absent variables or conflicting conditions.
      - [x] Align each macro with the corresponding requirement rows, verifying coverage of mandatory fields (e.g., `title-short`, `container-title`).
      - [x] Note mismatches in output formatting, such as missing punctuation or misordered elements, in `NOTES.md`.
      - [x] Identify where additional metadata (like `jurisdiction` or `collection-number`) must be surfaced in the input schema.
      - [x] Create an issues list prioritizing high-impact discrepancies that affect multiple authority types.
    - [x] Mark segments needing shared helper extraction or substitution fallbacks for later implementation tasks.
      - [x] Annotate inline comments within the CSL files (if permitted) or capture snippet references in `NOTES.md` describing the duplication.
      - [x] Determine whether the duplicated logic is best centralized as a macro, a conditional block, or a locale term.
      - [x] Estimate the implementation effort for each extraction candidate to aid later scheduling.
      - [x] Link each marked segment to the tests that currently cover or miss the associated behavior.
    - [x] Restore jurisdiction-aware branching in `cross-reference-cue` so statutes, rules, and agencies can emit “See also” for non-Texas authorities when `note` is empty (flagged in 2025-11-03 audit).
    - [x] Draft shared helpers for the code-section string and administrative core identified in the 2025-11-03 audit before wiring new short-form macros.
    - [x] Add undated treatise and CLE fixtures to `tests.json` once the year-fallback helper lands, ensuring the guard logic is regression-tested.
      - [x] Implement the `short-pinpoint-year` helper for short-form macros so missing years no longer leave trailing delimiters.
  - [ ] Outline Greenbook Chapter 10–13 short-form triggers (sections, chapters, and rule ranges) with page citations in `NOTES.md` to confirm requirements and edge cases.
    - [x] Read the relevant PDF sections and list each trigger verbatim with pinpoint page numbers.
      - [x] Use a PDF reader with search to locate discussions of short-form triggers within Chapters 10–13.
      - [x] Transcribe the trigger wording faithfully into `NOTES.md`, ensuring page numbers include subsection identifiers where available.
      - [x] Capture any diagrams or tables that illustrate exceptions, noting whether they affect citation structure.
      - [x] Confirm that references to appendices or footnotes are also recorded if they modify the main rule text.
    - [x] Translate each textual rule into structured conditions (e.g., `if section range && same title`) for CSL application.
      - [x] Define the exact metadata fields that correspond to each textual element (e.g., `section`, `chapter`, `rule-number`).
      - [x] Express compound conditions in pseudocode to check feasibility within CSL's `choose` and `if` constructs.
      - [x] Identify where helper macros or pre-processing may be required to satisfy the conditions.
      - [x] Document expected outputs for each condition, including punctuation and abbreviation requirements.
    - [x] Capture examples demonstrating exceptions (e.g., multi-source authorities) and log them in `NOTES.md`.
      - [x] Extract example citations from the PDF, recording full context sentences for accurate interpretation.
      - [x] Note whether the example references alternative reporters or cross-jurisdictional materials.
      - [x] Compare examples with the requirement matrix to ensure they map to existing or planned metadata fields.
      - [x] Flag examples lacking sufficient metadata in the test suite for future fixture creation.
    - [x] Validate the derived triggers against existing citation requirement matrices to ensure coverage alignment.
      - [x] Cross-reference each trigger with the matrix, noting any missing categories or contradictory instructions.
      - [x] Update the matrix or create addenda in `NOTES.md` when new conditions are discovered.
      - [x] Schedule follow-up tasks for triggers that cannot be implemented with current data structures.
      - [x] Seek clarification from subject-matter experts for ambiguous or conflicting trigger interpretations.
  - [ ] Extend `tests.json` with statute, rule, and administrative cross-reference scenarios that cover `Id.`, short-form without `Id.`, and cross-volume citations.
    - [x] Draft minimal input data for each scenario, noting required metadata fields (e.g., `volume`, `authority-type`).
      - [x] Create a spreadsheet or table listing each scenario with the metadata keys needed for citeproc to evaluate correctly.
      - [x] Reuse existing JSON templates to ensure field naming and nesting remain consistent.
      - [x] Identify any new metadata fields and document them for addition to data schemas or documentation.
      - [x] Gather example values from the Greenbook to populate realistic citation information.
      - [x] Queue fixtures for the Chapter 10–13 short-form gaps logged on 2025-11-04 (multi-section code cites, supplement parentheticals, amendment/repeal statuses, historical notes, judicial administration repeats, TRAP criminal appendix rules, and local court rules).
    - [x] Add fixture entries incrementally, verifying JSON schema compatibility via `run_tests.py --list-tests`.
      - [x] Insert one scenario at a time into `tests.json`, running the command after each addition to isolate syntax issues.
      - [x] Capture command output logs and store them in `temp/test-logs/` for traceability.
      - [x] Fix validation errors immediately, noting the resolutions in `NOTES.md`.
      - [x] Keep versioned backups of `tests.json` during the expansion to recover from accidental formatting errors.
    - [x] Annotate each new test case with Greenbook citations inside `tests.json` comments or in `NOTES.md`.
      - [x] Reference the relevant page numbers and rule identifiers next to each fixture entry.
      - [x] Include brief descriptions explaining the purpose of the test (e.g., `tests Id. short form`).
      - [x] Cross-link the annotations with the requirement matrix for consolidated documentation.
      - [x] Review annotations for clarity to assist future maintainers.
    - [x] Ensure both positive and negative cases exist to exercise fallback logic and `substitute` behavior.
      - [x] Design positive cases that confirm correct formatting when all metadata is present.
      - [x] Create negative cases that omit or alter key fields to trigger fallback logic, ensuring citeproc handles them gracefully.
      - [x] Document expected failure or fallback behavior next to each negative case.
      - [x] Verify that test coverage spans statutes, rules, and administrative materials equally.
  - [ ] Implement the shared short-form logic (including `substitute` fallbacks) within the style macros and mirror the changes into each TOA variant where applicable.
    - [ ] Prototype shared helper macros for repeated short-form behaviors before wiring them into case-specific blocks.
      - [ ] Draft macro skeletons that accept standardized parameters and return formatted strings.
      - [ ] Confirm the prototypes align with CSL syntax rules by validating with the CSL schema.
      - [ ] Share drafts with collaborators (if applicable) for feedback prior to integration.
      - [ ] Record design decisions, including naming conventions and parameter usage, in `NOTES.md`.
    - [ ] Replace duplicated conditional branches with helper macro calls, keeping regression snapshots for comparison.
      - [ ] Use version control diffs to confirm redundant code removal does not alter unrelated behavior.
      - [ ] Save intermediate snapshots of the CSL files to compare logic before and after helper insertion.
      - [ ] Document any dependencies that require updates due to macro refactoring.
      - [ ] Update inline comments to reflect the new helper usage for clarity.
    - [ ] Update TOA variants to reference the same helpers, ensuring variable availability matches note-style assumptions.
      - [ ] Verify that all helper macros are accessible within the TOA files and adjust import/`include` statements if necessary.
      - [ ] Test TOA-specific scenarios to ensure no missing variables cause blank outputs.
      - [ ] Record discrepancies between note and TOA requirements and adjust helper parameters accordingly.
      - [ ] Log TOA-specific considerations in `NOTES.md` for future maintenance.
    - [ ] Perform localized citeproc runs to confirm behavior prior to full fixture regeneration.
      - [ ] Execute targeted citeproc commands using sample CSL JSON data focusing on short-form outputs.
      - [ ] Capture outputs and compare them to expected results derived from the Greenbook examples.
      - [ ] Iterate on helper logic until outputs match expectations, documenting changes in `NOTES.md`.
      - [ ] Store command outputs in `temp/test-logs/` for reproducibility.
  - [ ] Regenerate `expected.txt` (and any affected TOA fixtures) with `run_tests.py --write-expected`, manually verify outputs against the Greenbook PDF, and document remaining discrepancies in `NOTES.md` if any.
    - [ ] Execute targeted tests for statute/rule citations and review diff outputs for unexpected formatting changes.
      - [ ] Run `python run_tests.py --filter statutes,rules` (or equivalent) to limit execution to relevant fixtures.
      - [ ] Inspect generated diffs using `git diff` to ensure only intentional formatting updates appear.
      - [ ] Capture screenshots or logs of significant diffs to aid later review.
      - [ ] Re-run tests after adjustments to confirm that unexpected changes are resolved.
    - [ ] Cross-check each regenerated citation with the authoritative PDF, noting page confirmations in `NOTES.md`.
      - [ ] Compare each output line with the Greenbook example, verifying abbreviations, spacing, and punctuation.
      - [ ] Note any deviations along with hypotheses for the discrepancy.
      - [ ] Update `NOTES.md` with cross-reference tables linking fixture IDs to PDF pages.
      - [ ] Seek sign-off from legal reviewers if discrepancies cannot be reconciled immediately.
    - [ ] Flag anomalies for follow-up (either additional TODO entries or clarifications) before finalizing fixtures.
      - [ ] Create new TODO entries or Git issues summarizing each anomaly with reproduction steps.
      - [ ] Assign priority levels (critical, blocker, informational) to triage future work.
      - [ ] Document interim workarounds or temporary assumptions in `NOTES.md`.
      - [ ] Communicate unresolved anomalies to collaborators via designated channels.
    - [ ] Commit regenerated fixtures alongside documentation updates once verification is complete.
      - [ ] Stage fixture and documentation files together to maintain traceability between code and notes.
      - [ ] Compose commit messages referencing the specific authorities or macros updated.
      - [ ] Verify that no extraneous files are staged prior to committing.
      - [ ] Push changes to a feature branch for review after passing all tests.
- [ ] **Finish explanatory parentheticals.** Add shared helpers for slip-opinion pinpoints, procedural parentheticals, and docket metadata so case and mandamus citations emit relief/status consistently before promoting the next edition revision.
    - [x] Compile the list of required explanatory parentheticals (slip opinion, procedural posture, relief granted, docket disposition) with page references from Chapters 2, 4, and 6 in `NOTES.md`.
      - [x] Read the specified chapters sequentially and bookmark sections discussing explanatory parentheticals.
      - [x] Extract verbatim language, noting whether examples differ between authority types.
      - [x] Record page numbers, section headers, and any footnote clarifications alongside each entry.
      - [x] Organize the list chronologically according to the chapter layout for quick cross-referencing later.
    - [ ] Extract sample parenthetical language verbatim from the PDF and capture contextual notes (case type, jurisdiction).
      - [ ] Use PDF text selection tools to avoid transcription errors and double-check formatting (italics, capitalization).
      - [ ] Note the authority type (e.g., civil appeal, mandamus) for each sample to ensure correct macro targeting.
      - [ ] Document whether the sample includes additional metadata such as docket numbers or writ history.
      - [ ] Store captured text snippets in a version-controlled appendix within `NOTES.md` or a dedicated attachment file.
    - [ ] Identify mandatory vs. optional elements within each parenthetical based on textual cues or examples.
      - [ ] Highlight words such as “must,” “shall,” or “may” in the PDF to determine requirement levels.
      - [ ] Create a decision table summarizing which elements are conditional and the criteria for inclusion.
      - [ ] Annotate ambiguous instructions with questions for legal review.
      - [ ] Reference each determination with precise page numbers for future audits.
    - [ ] Organize the parenthetical catalog by authority type in `NOTES.md` to simplify macro mapping.
      - [ ] Create sections or tables for cases, mandamus petitions, habeas proceedings, and other relevant categories.
      - [ ] Map each authority type to its corresponding CSL macro for immediate traceability.
      - [ ] Note overlapping requirements that could be served by shared helper macros.
      - [ ] Provide cross-links between catalog entries and existing test cases to highlight coverage gaps.
    - [ ] Highlight ambiguous directives requiring interpretation or additional research.
      - [ ] List unresolved questions in a dedicated subsection of `NOTES.md` with proposed follow-up actions.
      - [ ] Tag each ambiguity with its potential impact on implementation timelines.
      - [ ] Reference related external resources (e.g., Uniform Format Manual) that might clarify the ambiguity.
      - [ ] Schedule review meetings or consultation sessions if external expertise is needed.
  - [ ] Review existing macros handling parentheticals to identify duplicated logic between case notes and TOA outputs.
    - [x] Trace all macro invocations that append parenthetical content using CSL search tools.
      - [x] Search for keywords like “parenthetical” or specific strings (e.g., “slip op.”) within the CSL files using `rg`.
      - [x] Document each macro invocation path, including upstream macros and dependent outputs.
      - [x] Verify whether macros differ between note and bibliography contexts.
      - [x] Record findings in `NOTES.md`, citing file names and line ranges.
    - [x] Compare string construction patterns to determine where variables or punctuation diverge between outputs.
      - [x] Capture sample outputs from existing tests to illustrate the current formatting.
      - [x] Note inconsistencies such as missing commas or varying capitalization.
      - [x] Determine whether divergences stem from macro logic or locale terms.
      - [x] Propose standardization strategies and record them in `NOTES.md` for future action.
    - [x] Record duplication hotspots and opportunities for shared helper insertion in `NOTES.md`.
      - [x] Identify macros repeating similar conditional logic and list them in a consolidation table.
      - [x] Assess the effort required to merge each duplicated segment into a helper macro.
      - [x] Note dependencies (tests, documentation) that will need updates when duplication is removed.
      - [x] Prioritize hotspots according to frequency of use in the test suite or production citations.
    - [ ] Verify current behavior against existing fixtures to understand baseline expectations.
      - [ ] Run the parenthetical-related tests and store outputs for side-by-side comparison.
      - [ ] Check fixture expectations for coverage completeness and annotate any missing scenarios.
      - [ ] Document baseline quirks or known deviations that should persist after refactoring.
      - [ ] Share results with collaborators to establish consensus on the current state.
  - [ ] Design shared helper macros (e.g., `parenthetical-slip-op`, `parenthetical-procedural-status`, `parenthetical-docket`) that can be reused by case, mandamus, and habeas branches.
    - [ ] Draft pseudo-code for each helper detailing inputs, optional parameters, and output ordering.
      - [ ] Specify how each helper will handle absent metadata (e.g., omit text vs. insert placeholder).
      - [ ] Confirm parameter names align with existing CSL variable conventions.
      - [ ] Create flowcharts or tables illustrating the order of operations for complex helpers.
      - [ ] Store pseudo-code in `NOTES.md` for revision history and peer review.
    - [ ] Confirm helper naming and placement aligns with CSL best practices and repository conventions.
      - [ ] Review naming guidelines in `STYLE_REQUIREMENTS.md` or similar documentation.
      - [ ] Ensure helpers reside in logically grouped sections (e.g., near related macros).
      - [ ] Check for name collisions with existing macros across the repo.
      - [ ] Document the rationale for naming choices to support future maintenance.
    - [ ] Validate that helpers can accept jurisdiction-specific terminology without hard-coded strings.
      - [ ] Evaluate whether locale terms or variables can supply jurisdiction names dynamically.
      - [ ] Test prototype helpers with multiple jurisdiction inputs to confirm flexibility.
      - [ ] Record any cases where conditional logic must branch on jurisdiction attributes.
      - [ ] Update locale planning documents if additional terms are required.
    - [ ] Update `NOTES.md` with the planned helper interface for review before implementation.
      - [ ] Include function signatures, expected inputs, and sample outputs.
      - [ ] Request feedback from stakeholders and incorporate revisions.
      - [ ] Track version history of the interface description for future reference.
      - [ ] Note dependencies on other tasks (e.g., locale file creation) that may affect helper design.
  - [ ] Add targeted fixtures in `tests.json` and `expected.txt` for each parenthetical scenario, including combinations with petition history.
    - [ ] Create fixture entries covering slip opinions, mandamus relief, and habeas procedural notes with varied metadata.
      - [ ] Determine the minimal metadata required for each scenario and confirm availability within existing schemas.
      - [ ] Source realistic case names and docket details from the Greenbook or other authoritative references.
      - [ ] Populate JSON entries with both typical and edge-case data (e.g., consolidated cases, per curiam opinions).
      - [ ] Document each entry's intent and coverage area in `NOTES.md` or inline comments.
    - [ ] Ensure each fixture tests both note and bibliography contexts where applicable.
      - [ ] Duplicate scenarios across note and bibliography outputs if behavior should align.
      - [ ] Validate that citeproc renders both contexts without error messages or missing data.
      - [ ] Record any context-specific differences that should persist after helper implementation.
      - [ ] Update `expected.txt` counterparts to reflect both contexts accurately.
    - [ ] Capture petition history interactions by chaining multiple `related` entries in the test data.
      - [ ] Review CSL JSON schema to confirm correct usage of the `related` field for hierarchical relationships.
      - [ ] Construct sample data representing sequential petitions or appeals with varying outcomes.
      - [ ] Verify citeproc output preserves chronological order and punctuation.
      - [ ] Annotate complex relationships in `NOTES.md` to aid debugging.
    - [ ] Document fixture coverage and linked PDF citations in `NOTES.md`.
      - [ ] Create a matrix mapping each new fixture to its corresponding Greenbook rule and page number.
      - [ ] Record test file names and line numbers for quick lookup.
      - [ ] Summarize open coverage gaps requiring future fixtures.
      - [ ] Share the matrix with collaborators to facilitate peer review.
  - [ ] Implement the helpers, adjust macro routing for both note and TOA styles, and confirm citeproc output matches the Greenbook examples before finalizing documentation updates.
    - [ ] Insert helper macro calls into primary case citation pathways and remove redundant inline logic.
      - [ ] Update each affected macro sequentially, testing after every change to isolate regressions.
      - [ ] Note removed code blocks in commit messages or `NOTES.md` for historical context.
      - [ ] Ensure whitespace and indentation remain consistent following edits.
      - [ ] Verify that helper calls respect required variable scopes and fallback behavior.
    - [ ] Update TOA macro sequences to call the same helpers while preserving alphabetical grouping behavior.
      - [ ] Review TOA grouping logic to ensure helper insertion does not disrupt sorting or categorization.
      - [ ] Adjust helper output for TOA-specific punctuation if needed.
      - [ ] Run TOA-focused tests after each integration step and record outputs.
      - [ ] Document differences between note and TOA implementations to inform future maintenance.
    - [ ] Run incremental citeproc checks for each parenthetical type to validate punctuation and ordering.
      - [ ] Create targeted JSON datasets for each parenthetical scenario and execute citeproc locally.
      - [ ] Compare outputs with the compiled examples from the PDF, noting any remaining discrepancies.
      - [ ] Iterate on helper logic or data inputs until outputs align with authoritative guidance.
      - [ ] Archive the test commands and outputs in `temp/test-logs/` for reproducibility.
    - [ ] Revise documentation (`README.md`, `NOTES.md`) to describe the new helper architecture.
      - [ ] Update sections detailing macro flow, highlighting the introduction of shared helpers.
      - [ ] Add references to the relevant Greenbook pages supporting the changes.
      - [ ] Ensure diagrams or tables reflect the new logic pathways.
      - [ ] Proofread for clarity and solicit feedback before finalizing documentation.
- [ ] **Build shared publication/status helpers.** Create reusable macros for statutory publication parentheticals, session-law metadata, and administrative status notes to reduce duplication across code, rule, and agency citations.
    - [ ] Inventory where publication/status text is currently hard-coded across statute, session law, and administrative macros (main and TOA styles).
      - [ ] Search CSL files for publication-related strings using `rg "Supp\.|session|effective" temp` to locate occurrences.
      - [ ] Create a spreadsheet noting file names, macro contexts, and sample outputs for each string found.
      - [ ] Differentiate between main style and TOA usages to understand contextual differences.
      - [ ] Record whether each string is governed by locale terms or inline text.
    - [x] Use `rg` to list instances of publication-related strings (e.g., “Supp.”, “session”) within the CSL files.
      - [x] Capture command outputs and archive them in `temp/reports/` for future reference.
      - [x] Highlight potential false positives (e.g., comments or documentation) in the results.
      - [x] Annotate each match in `NOTES.md` with its authority type.
      - [x] Update the requirement matrix with any newly discovered terminology variations.
    - [x] Map each occurrence to the authority types it serves, noting duplication or inconsistent phrasing.
      - [x] Build a table linking macros to authority categories (statute, administrative, rule).
      - [x] Identify inconsistent capitalization or abbreviation usage between occurrences.
      - [x] Prioritize areas with the highest duplication for early helper implementation.
      - [x] Document inconsistencies requiring legal review or clarification.
    - [x] Record findings in `NOTES.md`, grouping by authority category for clarity.
      - [x] Summarize insights per category, including example citations and file references.
      - [x] Include screenshots or text snippets where helpful to illustrate context.
      - [x] Note cross-cutting themes (e.g., session law parentheticals sharing similar structure).
      - [x] Track outstanding questions or assumptions per category for follow-up.
    - [ ] Identify opportunities to consolidate similar strings before drafting helpers.
      - [ ] Suggest candidate helper names and describe their intended responsibilities.
      - [ ] Validate that consolidation will not break existing fixtures or edge cases.
      - [ ] Estimate time required for consolidation work to inform scheduling.
      - [ ] Capture risk assessments (e.g., potential regressions) in `NOTES.md`.
  - [ ] Extract common terminology requirements from Chapters 10–13 and Appendix A of the Greenbook, logging authoritative abbreviations in `NOTES.md`.
    - [ ] Read the specified chapters focusing on publication parentheticals and session law terminology.
      - [ ] Take detailed notes on required abbreviations, including variations by jurisdiction or publication year.
      - [ ] Compare textual guidance with examples to confirm consistent messaging.
      - [ ] Identify references to external manuals or appendices that may influence terminology.
      - [ ] Record page numbers and subheadings for each key term discovered.
    - [ ] Create a table of required abbreviations, including singular/plural and capitalization nuances.
      - [ ] Use a spreadsheet or Markdown table for clarity and ease of updates.
      - [ ] Indicate whether each abbreviation already exists in CSL locale files.
      - [ ] Highlight terms requiring conditional pluralization or gendered forms.
      - [ ] Track relationships between abbreviations and the authorities they modify.
    - [ ] Note any conflicting or context-dependent terms requiring conditional logic.
      - [ ] Document scenarios where terms change based on session type, historical period, or jurisdiction.
      - [ ] Propose conditional statements or metadata fields needed to resolve conflicts.
      - [ ] Flag terms that require legal review to ensure accurate interpretation.
      - [ ] Record references to supporting materials for each conflict.
    - [ ] Cross-reference terms with existing locale files to prevent redundancy.
      - [ ] Review CSL locale repositories for overlapping entries and note differences.
      - [ ] Determine whether existing terms can be reused via `<term form="short">` or similar constructs.
      - [ ] Update `NOTES.md` with decisions on reuse vs. new definitions.
      - [ ] Plan follow-up actions if upstream locale contributions are necessary.
    - [ ] Draft shared helper macros (e.g., `publication-parenthetical`, `session-law-metadata`, `administrative-status`) with parameters for date/session ranges and adoption/recodification notes.
      - [ ] Outline the data inputs required for each helper, referencing the metadata table built earlier.
      - [ ] Determine default behaviors when optional data is missing.
      - [ ] Validate that helper outputs can integrate seamlessly with existing citation macros.
      - [ ] Document design rationales, including trade-offs between flexibility and complexity.
    - [ ] Define macro signatures and document expected input variables in `NOTES.md` prior to coding.
      - [ ] Include example invocations demonstrating typical usage patterns.
      - [ ] Confirm compatibility with CSL processor expectations for parameter passing.
      - [ ] Note dependencies on upstream macros or locales.
      - [ ] Gather feedback from maintainers before finalizing signatures.
    - [ ] Prototype helper logic in isolated CSL snippets to confirm feasibility of parameter passing.
      - [ ] Use a sandbox CSL file to experiment with `choose` and `if` structures representing helper logic.
      - [ ] Run citeproc on the prototypes with sample JSON data to validate output.
      - [ ] Iterate on the prototypes until they handle all targeted cases.
      - [ ] Archive successful prototypes in `temp/prototypes/` for future reference.
    - [ ] Ensure helpers gracefully handle missing data using CSL conditional structures.
      - [ ] Test helper prototypes with intentionally incomplete metadata to confirm fallback behavior.
      - [ ] Document how each helper signals omitted information (e.g., blank output vs. placeholder text).
      - [ ] Update requirement matrices to reflect fallback strategies.
      - [ ] Capture lessons learned in `NOTES.md` for future helper development.
    - [ ] Prepare inline comments or `NOTES.md` explanations for complex conditional flows.
      - [ ] Draft concise comments summarizing each helper's decision tree.
      - [ ] Review comments for clarity and adherence to repository standards.
      - [ ] Maintain a changelog section within `NOTES.md` tracking revisions to helper logic.
      - [ ] Coordinate with reviewers to ensure explanations address anticipated questions.
  - [ ] Update style code to call the new helpers in all relevant branches, ensuring no duplication remains and TOA variants reference the same logic.
    - [ ] Replace hard-coded strings with helper invocations across main and TOA styles.
      - [ ] Perform replacements incrementally, running targeted tests after each batch to ensure stability.
      - [ ] Use search-and-replace tools carefully to avoid altering unrelated text.
      - [ ] Keep a checklist mapping each replaced string to its new helper usage.
      - [ ] Record before-and-after examples to demonstrate improvements.
    - [ ] Verify that helper calls respect existing variable scoping and citeproc evaluation order.
      - [ ] Review CSL documentation on variable precedence to avoid evaluation surprises.
      - [ ] Test scenarios where variables may be absent or overridden to ensure helpers behave correctly.
      - [ ] Adjust helper calls or macro structures if evaluation order causes regressions.
      - [ ] Document any quirks encountered for future maintainers.
    - [ ] Conduct spot tests on affected citation types to validate parenthetical output and formatting.
      - [ ] Run citeproc with representative JSON entries for statutes, session laws, and administrative decisions.
      - [ ] Compare outputs to authoritative examples, noting any mismatches.
      - [ ] Iterate on helper logic until outputs align with expectations.
      - [ ] Archive test logs and diff results alongside commit messages.
    - [ ] Remove obsolete macros or strings and document the refactor in `NOTES.md`.
      - [ ] Identify macros superseded by the new helpers and plan their removal carefully.
      - [ ] Update references throughout the CSL files to prevent dangling calls.
      - [ ] Note the removals in `NOTES.md` with justifications and cross-references to commits.
      - [ ] Verify tests remain green after cleanup to confirm no regressions.
  - [ ] Expand tests to include examples of session laws, codified statutes with publication notes, and administrative actions, then regenerate fixtures and document verification steps.
    - [ ] Add diverse authorities to `tests.json` capturing publication nuances and jurisdictional variations.
      - [ ] Draft metadata for session laws, codified statutes with supplements, and administrative orders.
      - [ ] Ensure coverage includes multiple jurisdictions and time periods.
      - [ ] Annotate each entry with its intended validation focus (e.g., session year range).
      - [ ] Store supporting references in `NOTES.md` for traceability.
    - [ ] Run citeproc to generate provisional outputs and review for adherence to Greenbook standards.
      - [ ] Execute `python run_tests.py --filter publication` (or similar) to evaluate the new fixtures.
      - [ ] Examine outputs for punctuation, abbreviation, and ordering accuracy.
      - [ ] Capture discrepancies along with recommended fixes.
      - [ ] Re-run tests after adjustments to confirm resolution.
    - [ ] Update `expected.txt` and relevant TOA fixtures, noting verification results with PDF citations.
      - [ ] Regenerate expectations using `run_tests.py --write-expected` once outputs are correct.
      - [ ] Compare the new expectations with PDF rules to ensure alignment.
      - [ ] Document verification steps and page citations in `NOTES.md`.
      - [ ] Store regenerated files under version control with descriptive commit messages.
    - [ ] Summarize new coverage areas and outstanding questions in `NOTES.md`.
      - [ ] Highlight which publication scenarios are now fully supported.
      - [ ] List remaining edge cases requiring future work.
      - [ ] Include references to updated fixtures and helper macros.
      - [ ] Share the summary with collaborators for feedback.

### Testing & Coverage
- [ ] **Expand Table of Authorities fixtures.** Introduce federal authorities and additional jurisdictional groupings to `tests_toa.json` and `expected_toa_*.txt` once the macro support exists.
  - [ ] Map the federal authority categories and grouping labels required by Appendix B, citing page numbers in `NOTES.md` for traceability.
    - [ ] Extract Appendix B tables outlining category names and ordering requirements.
    - [ ] Translate grouping labels into CSL term equivalents or new locale entries if necessary.
    - [ ] Identify dependencies on jurisdiction metadata fields to support grouping logic.
    - [ ] Document any unresolved mapping issues for follow-up research.
  - [ ] Determine the minimal set of sample citations (cases, statutes, administrative materials) needed to exercise each new grouping and leader combination.
    - [ ] List representative authorities for each category, ensuring coverage of unique edge cases (e.g., consolidated cases).
    - [ ] Specify required metadata attributes for each sample to ensure accurate sorting.
    - [ ] Check for overlap with existing fixtures to avoid redundancy while preserving coverage.
    - [ ] Record rationale for sample selection in `NOTES.md` with Appendix citations.
  - [ ] Add the new authorities to `tests_toa.json`, including jurisdiction metadata necessary for correct sorting and grouping.
    - [ ] Encode each sample authority in JSON, validating field names against existing schema.
    - [ ] Include grouping hints or categories in the test data to drive TOA leader formatting.
    - [ ] Run targeted TOA tests to confirm grouping behavior and adjust metadata as needed.
    - [ ] Annotate each JSON entry with references to the corresponding Greenbook guidance.
  - [ ] Update each `expected_toa*.txt` fixture to reflect the new authorities, running the TOA-specific styles to confirm alignment.
    - [ ] Execute `run_tests.py --write-expected --toa` (or equivalent) and review diff outputs for accuracy.
    - [ ] Compare generated grouping headers and indentation against Appendix B exemplars.
    - [ ] Resolve discrepancies by adjusting macros or test data before finalizing fixtures.
    - [ ] Log verification outcomes and any unresolved issues in `NOTES.md`.
  - [ ] Record any TOA macro adjustments or uncovered gaps in `NOTES.md` and feed follow-up tasks back into this TODO list if additional development is needed.
    - [ ] Summarize code changes affecting TOA behavior with references to modified macros.
    - [ ] Note remaining deficiencies and create new TODO entries or GitHub issues as appropriate.
    - [ ] Share insights on testing gaps to inform future fixture expansions.
    - [ ] Update the task checklist status reflecting completed and pending actions.
- [ ] **Broaden web citation verification.** Confirm punctuation and quotation usage for Chapter 16 web examples after OCR cleanup and add targeted fixture cases.
  - [x] Complete OCR cleanup for the Chapter 16 examples in the Greenbook PDF and extract verbatim sample citations into `NOTES.md` with page references.
    - [x] Run OCR tools (e.g., `ocrmypdf`) on the relevant PDF pages if not already processed.
    - [x] Manually proofread OCR output to correct typographical errors.
    - [x] Capture clean citation examples in `NOTES.md`, including context (e.g., government site, blog).
    - [x] Archive cleaned text snippets or references for future validation rounds.
  - [x] Compare existing web citation macros against the extracted examples to identify punctuation or quotation discrepancies.
    - [x] Trace macros generating web citations and annotate punctuation rules in `NOTES.md`.
    - [x] Perform side-by-side comparisons between citeproc output and extracted examples for each scenario.
    - [x] Catalog discrepancies by type (quotation marks, italics, commas) for targeted fixes.
    - [x] Prioritize discrepancies affecting authoritative compliance before cosmetic issues.
  - [ ] Create new fixture entries in `tests.json` that capture the nuanced web citation formats (e.g., with publication dates, access dates, and quoted titles).
    - [x] Enumerate required metadata fields for each format variant (e.g., missing author, corporate author).
    - [ ] Encode fixtures ensuring JSON validity and alignment with citeproc expectations.
    - [ ] Include commentary or IDs linking each fixture back to the source citation in `NOTES.md`.
    - [ ] Validate fixture coverage by simulating citeproc runs prior to updating expected outputs.
  - [ ] Update `expected_secondary.txt` (and related outputs) based on citeproc runs, verifying each change against the authoritative examples.
    - [ ] Regenerate expected outputs using `run_tests.py --write-expected` and confirm only targeted sections change.
    - [ ] Inspect punctuation and capitalization carefully, referencing Greenbook examples for each case.
    - [ ] Address any regressions introduced elsewhere in the fixtures before committing updates.
    - [ ] Document verification steps and outcomes in `NOTES.md` for reviewer transparency.
  - [ ] Document any remaining ambiguities or interpretive decisions in `NOTES.md` for future reviewers.
    - [ ] Summarize unresolved questions with proposed follow-up actions or references for escalation.
    - [ ] Highlight any dependencies on pending research tasks to maintain traceability.
    - [ ] Tag ambiguous items with TODO markers in `NOTES.md` for easy discovery.
    - [ ] Share context on decision-making rationale to aid future maintainers.

## Research & Backlog
- [x] **Resolve memo opinion styling.** Verify italicization requirements for unpublished memorandum opinions (Greenbook Ch. 4, pp. 24–25) before locking typography rules.
  - [x] Extract the memo opinion examples from the PDF and note the typography treatment (italics, capitalization, spacing) with precise citations in `NOTES.md`. (Documented representative examples from pp. 16–18 in the memo opinion typography check dated 2025-11-01.)
    - [x] Capture screenshots or text snippets of each example for visual comparison. (Added verbatim text snippets for Richardson v. Kays, In re Int’l Profit Assocs., Green v. State, and Jaxson v. Morgan to `NOTES.md`.)
    - [x] Annotate typography rules (e.g., italicized case names vs. roman text) per example. (Recorded roman treatment for `(per curiam)` and `(mem. op.)` parentheticals alongside italicized case names.)
    - [x] Record any conflicting guidance between text and examples for later clarification. (No conflicts surfaced; noted alignment with Chapter 1 conventions.)
    - [x] Store references to PDF page numbers and figure labels in `NOTES.md`. (Cited Greenbook Chapter 4 pages in the new memo opinion typography section.)
  - [x] Review the current case macros to determine how memo opinion indicators are applied in both main and TOA outputs.
    - [x] Identify macro sections inserting memo opinion signals (e.g., “mem. op.”) and log their formatting.
    - [x] Compare note vs. TOA outputs to ensure consistent typography handling.
    - [x] Evaluate interactions with parenthetical helpers to anticipate cascading changes.
    - [x] Document current implementation limitations in `NOTES.md`.
  - [x] If adjustments are required, design the preferred formatting approach (e.g., new terms vs. styling attributes) and outline the implementation steps.
    - [x] Draft alternative formatting strategies and assess compatibility with CSL capabilities. (Chose explicit `font-style="normal"` guards rather than introducing locale terms.)
    - [x] Select the approach aligning best with Greenbook directives and repository conventions.
    - [x] Produce a mini design doc in `NOTES.md` enumerating required macro updates.
    - [x] Solicit feedback from collaborators (if applicable) before coding. (N/A during solo run.)
  - [x] Prototype the change in a feature branch or local draft, run targeted tests, and evaluate against the Greenbook examples.
    - [x] Implement experimental modifications in a sandbox version of the style.
    - [x] Execute citeproc runs focusing on memo opinion cases to gather output samples.
    - [x] Compare outputs with PDF examples and iterate until alignment is achieved.
    - [x] Record lessons learned and final decisions in `NOTES.md`.
  - [x] Update this TODO item with the chosen solution and file any residual questions in `NOTES.md`.
    - [x] Check off completed subtasks and adjust the main TODO entry to reflect status.
    - [x] List outstanding issues requiring future attention or upstream consultation. (Memo styling now closed; no follow-ups required.)
    - [x] Ensure `NOTES.md` captures closure details and references to supporting tests.
    - [x] Communicate updates to collaborators or maintainers via shared channels if relevant. (Not needed for solo run; documented in repo.)
- [x] **Decide on shared locale packaging.** Draft the consolidated locale file for terms like “art.” and “ch.” and plan integration across all drafts per the standing assumption. (Validated locale metadata and documented final review in `NOTES.md` on 2025-11-02.)
  - [x] Identify all non-default terms currently overridden in the main and TOA styles, listing them in `NOTES.md` along with their source citations.
    - [x] Scan CSL files for `<term>` overrides or localized string literals.
    - [x] Compile a table mapping each term to its use-case and associated Greenbook citation.
    - [x] Verify whether terms require pluralization or gender variants for locale coverage.
    - [x] Note duplicate or conflicting overrides needing consolidation.
  - [x] Confirm whether the standalone `and` override needs a dedicated Greenbook citation or can defer to the default locale; record the decision path in `NOTES.md`.
  - [x] Determine whether existing CSL locales cover these terms or if a custom `locales-en-US-x-texas-greenbook.xml` (or similar) file is required.
    - [x] Review stock CSL locale files to identify overlapping term definitions.
    - [x] Assess compatibility of existing locales with Greenbook-specific abbreviations.
    - [x] Decide on the necessity of a custom locale and document justification in `NOTES.md`.
    - [x] Outline integration implications (e.g., repository structure, packaging requirements).
  - [x] Draft the shared locale file structure, including `<term>` entries for abbreviations and any required pluralization forms.
    - [x] Sketch the XML schema layout, ensuring compliance with CSL locale standards.
    - [x] Populate placeholder entries for each required term with notes on capitalization and punctuation.
    - [x] Validate XML syntax using available tooling (e.g., `xmllint`).
    - [x] Record mapping between locale entries and style macros for traceability.
  - [x] Confirm whether the shared locale needs a distinct dialect code (e.g., `en-US-x-texas-greenbook`) before upstream submission and update the filename/`xml:lang` pairing accordingly.
  - [x] Add required CSL locale metadata (`version`, `<style-options>`, `<date>`) to `temp/locales/locales-en-US-x-texas-greenbook.xml` so the shared file validates before upstream submission. (Added version attribute, Creative Commons license, ISO-8601 updated timestamp, text/numeric date formats, and US punctuation-in-quote defaults on 2025-11-01.)
  - [x] Plan how the locale file will be distributed (e.g., bundled in this repository vs. submitted upstream) and document integration steps for each style.
    - [x] Review CSL upstream contribution policies regarding locale files.
    - [x] Determine versioning strategy and update pathways for consumers of the styles.
    - [x] Draft integration instructions for including the locale in build/test workflows.
    - [x] Capture open questions about packaging or dependency management in `NOTES.md`.
  - [x] Schedule updates to the styles and tests that will consume the locale file, noting dependencies or sequencing constraints in this TODO list.
    - [x] Identify which style files require modifications once the locale is available.
    - [x] Sequence tasks to minimize merge conflicts with ongoing macro work.
    - [x] Align test fixture updates with locale deployment to avoid inconsistent outputs.
    - [x] Update the TODO timeline or roadmap reflecting these dependencies.
- [ ] **Investigate supplemental references.** Follow up on OCR availability for the Uniform Format Manual and confirm TRCP/TRAP cross-references and historical reporter sources listed in `NOTES.md`.
  - [x] Verify OCR readiness or perform text extraction for the supplemental manuals (Uniform Format Manual, rulemaking history PDFs) and store accessible copies or summaries. (2025-11-02 PyPDF2 spot-check confirmed existing PDFs remain searchable; no new exports required.)
    - [x] Check existing repositories or archives for machine-readable versions before initiating OCR. (Existing in-repo PDFs are text-searchable; no replacements needed.)
    - [x] If OCR is needed, select tooling, configure language options, and process the documents. (Not required; confirmed originals provide selectable text.)
    - [x] Review output for accuracy, correcting errors or marking unclear sections for follow-up. (Sample extractions from each manual read cleanly; no corrections necessary.)
    - [x] Save processed text in `temp/` or a referenced location with clear filenames. (Retained canonical PDFs in `temp/`; no additional derivatives needed.)
  - [x] Cross-reference TRCP/TRAP citations in `NOTES.md` with the supplemental materials to validate abbreviations and historical reporter references.
    - [x] Build a comparison table aligning `NOTES.md` entries with supplemental source terminology.
    - [x] Highlight discrepancies in abbreviations or reporter names needing resolution.
    - [x] Document confirmation of matches with precise page or section references.
    - [x] Escalate any conflicting guidance to legal editors or subject-matter experts if necessary.
  - [x] Update `NOTES.md` with confirmed cross-references, including any discrepancies or areas needing authoritative clarification.
    - [x] Summarize validation outcomes per citation type (TRCP, TRAP, reporters).
    - [x] Record open questions with proposed next steps or responsible parties.
    - [x] Ensure entries include page numbers and document identifiers for traceability.
    - [x] Tag updates with timestamps or authorship notes if collaborative tracking is required.
  - [x] Identify whether additional fixtures or macros are needed based on findings and create follow-up TODO entries if required. (Reviewed supplemental manuals against current fixtures on 2025-11-01 and confirmed coverage is sufficient.)
    - [x] Evaluate whether uncovered abbreviations necessitate new style logic or locale terms. (All supplemental abbreviations align with existing locale entries; no new terms required.)
    - [x] Draft new fixture requirements capturing supplemental authority nuances. (Determined that statute, rule, and agency fixtures already exercise the verified abbreviations, so no new scenarios are needed yet.)
    - [x] Add corresponding TODO items or Git issues with clear descriptions and prerequisites. (No additional tasks opened; will revisit if future research exposes uncovered authority classes.)
    - [x] Communicate new tasks to collaborators to align workload. (Recorded the outcome in `NOTES.md` under “Supplemental reference gap review (2025-11-01)” to keep contributors informed.)
  - [x] Document the status of supplemental reference acquisition so future contributors know where canonical sources reside.
    - [x] Create a summary section in `NOTES.md` listing storage locations and access instructions.
    - [x] Note any licensing or usage restrictions associated with the supplemental materials.
    - [x] Include backup strategies or mirror locations to prevent data loss.
    - [x] Provide contact information or links for requesting updated editions if applicable.

## Release Preparation
- [ ] **Finalize submission checklist.** Once logic gaps close, run `run_tests.py` suites, refresh documentation, and prepare the PR narrative referencing key Greenbook sections.
  - [ ] Confirm that all Active Development tasks are checked off and corresponding tests/fixtures are current.
    - [ ] Review each Active Development checklist item for completion status and update boxes accordingly.
    - [ ] Verify test fixtures reflect latest logic changes by diffing against previous baselines.
    - [ ] Note outstanding dependencies preventing closure and escalate if needed.
    - [ ] Document completion evidence (commit hashes, test logs) in `NOTES.md`.
  - [ ] Execute the full battery of regression tests for both note and TOA styles, capturing command output for inclusion in the eventual PR summary.
    - [ ] Run `python run_tests.py --all` (or equivalent) and capture logs with timestamps.
    - [ ] Re-run failing suites after addressing issues to confirm stability.
    - [ ] Store command outputs in `temp/test-logs/` or reference location for PR documentation.
    - [ ] Summarize notable test coverage notes in `NOTES.md`.
  - [ ] Sweep documentation (`README.md`, `NOTES.md`, `TODO.md`) to ensure they reflect the completed work, Greenbook citations, and outstanding questions.
    - [ ] Perform a structured read-through of each document, updating sections for accuracy and completeness.
    - [ ] Insert new Greenbook page references where additional rules were implemented.
    - [ ] Remove outdated information or relocate it to archival sections if still relevant.
    - [ ] Proofread for clarity and consistency prior to final review.
  - [ ] Draft the PR narrative aligning with CSL submission requirements (title, summary, documentation links) and note specific Greenbook sections referenced during implementation.
    - [ ] Outline key feature changes and bug fixes with supporting citations.
    - [ ] Prepare a checklist of repository requirements (e.g., style validity, tests passing) to include in the PR body.
    - [ ] Compose draft PR text and store it in `temp/PR_DRAFT.md` for review.
    - [ ] Solicit feedback from collaborators or run a self-review against CSL contribution guidelines.
  - [x] Review the CSL repository contribution guidelines (`CONTRIBUTING.md`, `STYLE_REQUIREMENTS.md`) to double-check readiness before packaging the submission.
    - [x] Re-read the guidelines and highlight any new or updated requirements since project start.
    - [x] Ensure documentation and style files satisfy formatting, metadata, and licensing expectations.
    - [x] Confirm changelog or submission metadata needs (if any) are addressed.
    - [x] Update this TODO entry to reflect guideline compliance status and next steps.
