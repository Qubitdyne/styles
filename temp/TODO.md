# Texas Greenbook 15th Edition CSL Development TODO

## Legend & Status Conventions
- [x] Completed item.
- [ ] Outstanding item awaiting work.
- Nested checklists enumerate the full subtask inventory required to complete each parent entry, so clearing a parent task requ
ires checking off every indented child.

## Completed Work
- [x] **Familiarized with source material.** Cataloged rule coverage, appendices, and page citations from the Greenbook PDF and logged them in `NOTES.md` for traceability.
  - [x] Read the entire Greenbook PDF, bookmarking chapters with unresolved CSL implications for later reference.
  - [x] Indexed each citation rule with page and section numbers inside `NOTES.md`, using consistent anchors for cross-linking.
  - [x] Captured appendix abbreviations and tables in a structured outline to inform locale and macro design decisions.
  - [x] Flagged ambiguous or conflicting guidance in `NOTES.md` with follow-up questions for future research tasks.
- [x] **Surveyed existing CSL styles.** Reviewed Bluebook-derived and legal-dependent templates, noting reusable macros and locale patterns in `NOTES.md`.
  - [x] Audited representative legal CSL styles (e.g., Bluebook, ALWD) to assess reusable macro patterns.
  - [x] Documented locale overrides and jurisdiction handling strategies that could translate to the Greenbook effort.
  - [x] Logged promising helper macros and structural motifs in `NOTES.md`, including file paths for quick lookup.
  - [x] Identified gaps in existing styles that necessitated bespoke Texas-specific implementations.
- [x] **Defined citation requirements.** Produced the citation requirement matrix with mandatory variables, abbreviations, and Greenbook page references.
  - [x] Compiled authority categories (cases, statutes, regulations, secondary sources) with required CSL variables.
  - [x] Cross-referenced each requirement with the corresponding Greenbook rule citations.
  - [x] Added abbreviation guidance from Appendix A into the matrix to drive locale planning.
  - [x] Validated the matrix against sample citations to ensure metadata coverage was sufficient.
- [x] **Designed style architecture.** Established the macro routing now preserved in `texas-greenbook-15th-edition.csl` and its Table of Authorities variants.
  - [x] Drafted macro dependency diagrams outlining note, bibliography, and TOA entry points.
  - [x] Segmented authority handling into reusable helpers to minimize duplication between style variants.
  - [x] Verified that macro names and scopes conform to CSL schema conventions.
  - [x] Recorded architectural rationale and known trade-offs in `NOTES.md` for reviewer transparency.
- [x] **Drafted primary CSL files.** Authored legacy drafts (`draft0`–`draft3`, now archived) along with TOA counterparts covering primary authorities.
  - [x] Iteratively produced draft styles capturing incremental rule coverage milestones.
  - [x] Archived superseded drafts under `temp/archive/` with descriptive filenames for historical traceability.
  - [x] Maintained synchronization between note and TOA variants during each drafting round.
  - [x] Documented milestone achievements and remaining gaps at the end of each draft cycle.
- [x] **Implemented secondary source rules.** Completed book-, journal-, CLE-, and web-specific macros shared between citation and bibliography outputs.
  - [x] Cataloged secondary source authority types with Greenbook references prior to implementation.
  - [x] Built shared macros for contributors, pinpoint references, and access dates usable across multiple item types.
  - [x] Validated outputs against Greenbook examples and captured deviations in `NOTES.md`.
  - [x] Synced TOA handling for secondary materials where applicable or documented exclusions.
- [x] **Created regression fixtures.** Added `tests.json`, `tests_toa.json`, and matching `expected*.txt` files for authorities and TOA scenarios.
  - [x] Authored representative citeproc JSON entries for each authority class covered by the drafts.
  - [x] Generated baseline expected outputs using the current CSL implementations.
  - [x] Stored fixture provenance (rule citations, assumptions) directly in `NOTES.md` for auditability.
  - [x] Organized fixtures into logical groupings (general, secondary, TOA) to streamline targeted testing.
- [x] **Prepared working documentation.** Wrote the `README.md` overview, expanded research `NOTES.md`, and tracked assumptions and deviations.
  - [x] Summarized repository contents and workflow expectations in `temp/README.md`.
  - [x] Populated `NOTES.md` with research findings, open questions, and design decisions linked to Greenbook citations.
  - [x] Established `TODO.md` as the living backlog, aligning entries with documentation anchors.
  - [x] Reviewed documents for consistency and clarity before marking the preparation complete.

## Active Development
### Citation Logic Gaps
- [ ] **Complete statute and rule short-form logic.** Implement cross-reference and `Id.` handling for statutes, rules, and administrative materials, then update `expected.txt` fixtures. (See `README.md` Known Limitations and `NOTES.md` helper sketches.)
  - [x] Audit the existing statute, rule, and administrative `*_short` macros in `texas-greenbook-15th-edition.csl` to catalog current branching and pinpoint missing reuse hooks documented in `NOTES.md`.
    - [x] Locate all `*_short` macros in both the primary style and TOA variants using the CSL editor or `rg` searches.
      - [x] Run `rg "_short" temp -n` to generate an initial list of macro definitions and invocations. (Confirmed command currently only surfaces backlog references because implemented macros are hyphenated; noted follow-up in `NOTES.md`.)
      - [x] Open `texas-greenbook-15th-edition.csl` and TOA counterparts in a CSL-aware editor to confirm the matches and capture surrounding context. (Verified short-form coverage for cases/secondary materials and documented absence in TOA variants.)
      - [x] Copy the macro names and file locations into `NOTES.md`, grouping them by authority type for easy reference. (Inventory logged under “Short-form macro inventory (2025-11-02)”.)
      - [x] Flag any macros with ambiguous naming or duplicate purposes for follow-up clarification tasks.
        - [x] Review each inventoried macro name against its implementation to confirm the intended scope and avoid overlaps.
        - [x] Document ambiguous or duplicated macros in `NOTES.md`, including file names, line ranges, and a concise descript
ion of the conflicting behavior.
        - [x] Draft proposed resolutions (rename, consolidate, or split) and record the rationale alongside related requirement
 matrix entries.
        - [x] Create follow-up TODO entries or GitHub issues for any macros that require broader refactors or reviewer input. (2025-11-02 review confirmed existing backlog coverage; no new entries required beyond the standing short-form epic noted in `NOTES.md`.)
    - [x] Diagram current conditional logic and data dependencies for each macro in `NOTES.md` to identify overlapping pathways.
      - [x] For every macro captured, sketch the `if/else` and `choose` structures, noting required variables and fallback behavior.
      - [x] Highlight reuse of helper macros or localized terms to map dependency chains accurately.
      - [x] Record gaps where inputs are assumed but not enforced, marking them for later validation tooling.
      - [x] Include references to relevant lines or sections within the CSL files so diagrams can be quickly cross-checked.
    - [x] Compare macro inputs/outputs with the requirement matrix to spot absent variables or conflicting conditions.
      - [x] Align each macro with the corresponding requirement rows, verifying coverage of mandatory fields (e.g., `title-short`, `container-title`).
      - [x] Note mismatches in output formatting, such as missing punctuation or misordered elements, in `NOTES.md`.
      - [x] Identify where additional metadata (like `jurisdiction` or `collection-number`) must be surfaced in the input schema.
      - [x] Create an issues list prioritizing high-impact discrepancies that affect multiple authority types.
    - [x] Mark segments needing shared helper extraction or substitution fallbacks for later implementation tasks.
      - [x] Annotate inline comments within the CSL files (if permitted) or capture snippet references in `NOTES.md` describing the duplication.
      - [x] Determine whether the duplicated logic is best centralized as a macro, a conditional block, or a locale term.
      - [x] Estimate the implementation effort for each extraction candidate to aid later scheduling.
      - [x] Link each marked segment to the tests that currently cover or miss the associated behavior.
    - [x] Restore jurisdiction-aware branching in `cross-reference-cue` so statutes, rules, and agencies can emit “See also” for non-Texas authorities when `note` is empty (flagged in 2025-11-03 audit).
    - [x] Draft shared helpers for the code-section string and administrative core identified in the 2025-11-03 audit before wiring new short-form macros.
    - [x] Add undated treatise and CLE fixtures to `tests.json` once the year-fallback helper lands, ensuring the guard logic is regression-tested.
      - [x] Implement the `short-pinpoint-year` helper for short-form macros so missing years no longer leave trailing delimiters.
  - [ ] Implement short-form macros for statutes, rules, and administrative materials in the main style.
    - [ ] Create dedicated macros (e.g., `tex-statute-short`, `tex-rule-short`, `tex-administrative-short`) that mirror the long-form structure while applying the short-form requirements documented in `NOTES.md`.
      - [x] Review the existing long-form macros to list the elements that must persist in short form and highlight pieces to omit.
      - [x] Draft pseudo-code for each short-form macro, mapping inputs to outputs alongside the corresponding Greenbook citations.
      - [x] Implement macro shells in the CSL file, copying structural boilerplate (comments, indentation) from comparable case short forms.
      - [x] Run citeproc on a minimal JSON dataset to confirm each macro compiles before layering conditional logic.
      - [x] Annotate the new macro definitions with inline comments referencing the requirement matrix row or `NOTES.md` anchor for quick audits.
    - [ ] Add `choose` blocks to differentiate between first-reference short cites, cross-references, and `Id.` scenarios, ensuring jurisdictional fallbacks work for both Texas and non-Texas authorities.
      - [x] Enumerate the triggering conditions for each branch (first short cite, cross-reference, `Id.`) and link them to metadata fields (e.g., `first-reference-note-number`, `ibid`).
      - [ ] Encode the branching logic within the macros, double-checking that `jurisdiction` and `authority` comparisons align with existing helper conventions.
      - [ ] Test each branch using targeted JSON fixtures that force the macro into the intended path.
      - [ ] Verify punctuation and spacing for every branch against the PDF examples, adjusting delimiters or affixes as needed.
      - [ ] Document unresolved edge cases (e.g., missing sections, unusual jurisdiction abbreviations) in `NOTES.md` for future refinement.
    - [ ] Integrate the new macros into existing routing (e.g., `legal-reference-note`, `statute-reference`) without regressing current case or secondary short-form behavior.
      - [ ] Identify all invocation points for statute, rule, and administrative authorities and replace placeholder calls with the new short-form macros.
      - [ ] Ensure helper macros supplying shared strings (e.g., `code-section-string`) are reused instead of duplicating literal text.
      - [ ] Run the full note test suite after each integration pass to catch regressions early.
      - [ ] Compare outputs with pre-change expectations, noting intentional differences tied to the short-form rollout.
      - [ ] Stage incremental commits or stash checkpoints so regressions can be isolated if encountered.
    - [ ] Capture interim outputs and logic decisions in `NOTES.md`, citing relevant Greenbook pages for each branch.
      - [ ] Log the rationale for each conditional structure, including page citations and paraphrased rule text.
      - [ ] Save representative citeproc outputs (before and after adjustments) in `temp/test-logs/` and cross-reference them from the notes.
      - [ ] Summarize gaps discovered during implementation and flag them as follow-up TODO items if they fall outside the current scope.
      - [ ] Record open questions that require legal review, tagging them with owners or target review dates if applicable.
      - [ ] Update the citation requirement matrix to reflect any additional metadata dependencies uncovered during coding.
  - [ ] Mirror the short-form implementation into TOA variants and shared helpers.
    - [ ] Add corresponding macros or conditional blocks to each `texas-greenbook-15th-toa*.csl` file, maintaining consistent terminology with the main style.
      - [ ] Copy the finalized short-form macro structure into each TOA file, renaming identifiers only when necessary for style isolation.
      - [ ] Align TOA macro ordering with the note style to simplify future diffs and reviews.
      - [ ] Confirm that TOA variants call the same helper macros as the primary style rather than duplicating logic inline.
      - [ ] Record any TOA-only deviations (e.g., omission of italics) directly in the file comments for reviewer context.
    - [ ] Verify that TOA grouping and dotted leader alignment remain intact after introducing short-form routing.
      - [ ] Run TOA-specific citeproc tests for each variant and inspect the generated leaders for spacing shifts.
      - [ ] Compare outputs to baseline `expected_toa*.txt` files to ensure categories remain in the correct order.
      - [ ] Adjust macro placements if the new short-form calls interfere with leader generation or indentation.
      - [ ] Capture before/after screenshots or text snippets in `temp/test-logs/` to document the alignment check.
    - [ ] Update any shared helper macros so TOA and note styles reuse the same short-form formatting strings.
      - [ ] Review helper definitions (e.g., `short-form-body`, `code-section-string`) to confirm they accept both note and TOA contexts.
      - [ ] Add parameters or conditional switches when TOA output needs alternate punctuation.
      - [ ] Re-run both note and TOA tests after helper modifications to ensure compatibility.
      - [ ] Summarize helper updates in `NOTES.md`, noting any new dependencies or assumptions introduced.
    - [ ] Document TOA-specific adjustments (e.g., leader punctuation) in `NOTES.md` with citations to Appendix B requirements.
      - [ ] Link each documented adjustment to the relevant Appendix B page number and style file line range.
      - [ ] Highlight any deviations from Appendix examples and justify the CSL implementation choices.
      - [ ] Flag open questions about TOA formatting (if any) for later review in the Release Preparation phase.
      - [ ] Update the TOA section of the requirement matrix to reflect the finalized short-form behavior.
  - [ ] Extend cross-reference cue logic for statutes, rules, and agencies.
    - [ ] Update the `cross-reference-cue` macro so that blank `note` fields trigger “See also” outputs for non-Texas authorities while preserving existing case handling.
      - [ ] Trace current `cross-reference-cue` execution paths to confirm where the note value is evaluated.
      - [ ] Add conditional checks for statute, rule, and administrative authority types, reusing existing jurisdiction helpers when possible.
      - [ ] Verify that the macro still returns empty output when `note` contains substantive text, avoiding redundant cues.
      - [ ] Run citeproc scenarios with mixed Texas and non-Texas authorities to confirm the cue renders only in the expected cases.
      - [ ] Update inline comments or `NOTES.md` to document the new logic with Greenbook references.
    - [ ] Ensure statute/rule short forms properly interpret `ibid`-style references, respecting Greenbook triggers for when `Id.` is permitted.
      - [ ] Review the CSL `ibid` handling configuration to understand current processor behavior for statutes and rules.
      - [ ] Add conditional guards within the short-form macros that suppress `Id.` when the Greenbook disallows it (e.g., cross-title citations).
      - [ ] Test with sequential citations that should and should not produce `Id.` to validate the guard logic.
      - [ ] Document exceptions (such as session law sequences) that require future enhancements beyond the initial implementation.
      - [ ] Capture example outputs demonstrating compliant `Id.` usage and archive them with test logs.
    - [ ] Add regression tests covering cross-jurisdiction references and `Id.` fallbacks.
      - [ ] Expand `tests.json` with pairs of citations representing Texas vs. non-Texas authorities to trigger the new cue behavior.
      - [ ] Include note sequences that alternate between eligible and ineligible `Id.` contexts to exercise the guards.
      - [ ] Generate updated `expected*.txt` outputs and verify that cues and `Id.` usage match Greenbook expectations.
      - [ ] Store the corresponding citeproc commands and outputs in `temp/test-logs/` for reproducibility.
    - [ ] Record any limitations or open questions in `NOTES.md` for follow-up review.
      - [ ] Summarize edge cases deferred from the current sprint (e.g., multi-jurisdiction compound cites).
      - [ ] Tag questions with the responsible owner or review milestone if collaboration is anticipated.
      - [ ] Reference the specific CSL line numbers where ambiguity remains to expedite future debugging.
      - [ ] Update the TODO backlog with newly identified follow-up tasks to keep planning aligned.
  - [ ] Update fixtures and expectations to exercise the new short-form logic.
    - [ ] Add representative statute, rule, and administrative authorities to `tests.json` and `tests_toa.json`, including scenarios with and without available years.
      - [ ] Gather example citations from the Greenbook and supplemental manuals to ensure realistic metadata coverage.
      - [ ] Populate JSON entries with explicit notes on which macro branch they are intended to exercise (cross-reference, `Id.`, non-Texas).
      - [ ] Validate each new entry with `python temp/run_tests.py --list-tests` to confirm schema compliance before committing.
      - [ ] Track additions in a change log table within `NOTES.md`, linking each fixture to a PDF page reference.
    - [ ] Regenerate `expected.txt`, `expected_secondary.txt`, and TOA counterparts using `run_tests.py --write-expected`, reviewing diffs for alignment with the Greenbook examples.
      - [ ] Run the write-expected command separately for note and TOA suites to isolate any anomalies.
      - [ ] Review generated diffs line-by-line, annotating intentional changes vs. unexpected variations.
      - [ ] Re-run citeproc after addressing anomalies to confirm stable expectations.
      - [ ] Record the command invocations and timestamps in `temp/test-logs/` for reproducibility.
    - [ ] Store citeproc command outputs in `temp/test-logs/` to document verification.
      - [ ] Save raw command output files using descriptive filenames (e.g., `2025-11-20-short-form-write-expected.txt`).
      - [ ] Include summary headers in each log noting the related TODO item and data set exercised.
      - [ ] Cross-reference the log filenames within `NOTES.md` so reviewers can locate them quickly.
      - [ ] Periodically prune superseded logs to prevent confusion, archiving critical milestones as needed.
    - [ ] Note fixture provenance and rule citations in `NOTES.md` to keep the regression inventory auditable.
      - [ ] Update the fixture matrix with new entries, capturing authority type, purpose, and Greenbook citation.
      - [ ] Highlight any fixtures that rely on assumptions or inferred data, noting the justification.
      - [ ] Document reviewer sign-offs or pending approvals for fixtures derived from ambiguous guidance.
      - [ ] Link to any external resources (e.g., PDFs, spreadsheets) that house additional context for the test data.
  - [ ] Refresh documentation after implementation completes.
    - [ ] Update `README.md` Known Limitations to reflect the closure of statute/rule short-form gaps.
      - [ ] Draft revised language removing the limitation and briefly describing the implemented solution.
      - [ ] Insert citations to the relevant Greenbook sections supporting the implemented behavior.
      - [ ] Proofread the updated section for tone and clarity, ensuring it matches the rest of the README.
      - [ ] Capture before/after snippets in `NOTES.md` to document the documentation change.
    - [ ] Summarize macro additions and test coverage changes in `NOTES.md` with Greenbook citations.
      - [ ] Create a changelog entry listing new macros, helpers, and associated file paths.
      - [ ] Reference specific Greenbook rules for each addition to maintain traceability.
      - [ ] Highlight new or updated fixtures and include links to their test log evidence.
      - [ ] Note any follow-up actions or pending questions related to the short-form work.
    - [ ] Revise `TODO.md` to mark completed subtasks and capture any deferred edge cases for future work.
      - [ ] Check off completed checkboxes and adjust task descriptions to reflect the latest status.
      - [ ] Add new unchecked bullets for edge cases deferred during implementation, referencing `NOTES.md` anchors.
      - [ ] Reorder items if necessary to keep chronological or priority flow intuitive.
      - [ ] Commit the updated TODO with a descriptive message summarizing the changes.
    - [ ] Ensure `temp/PR_DRAFT.md` references the new short-form support for eventual submission notes.
      - [ ] Insert a summary paragraph in the PR draft highlighting the short-form implementation and test coverage.
      - [ ] Add bullet points linking to relevant documentation or test logs for reviewers.
      - [ ] Review the draft against CSL submission guidelines to confirm tone and required metadata.
      - [ ] Schedule a final proofread during Release Preparation to capture any late-breaking updates.
  - [x] Outline Greenbook Chapter 10–13 short-form triggers (sections, chapters, and rule ranges) with page citations in `NOTES.md` to confirm requirements and edge cases.
    - [x] Read the relevant PDF sections and list each trigger verbatim with pinpoint page numbers.
      - [x] Use a PDF reader with search to locate discussions of short-form triggers within Chapters 10–13.
      - [x] Transcribe the trigger wording faithfully into `NOTES.md`, ensuring page numbers include subsection identifiers where available.
      - [x] Capture any diagrams or tables that illustrate exceptions, noting whether they affect citation structure.
      - [x] Confirm that references to appendices or footnotes are also recorded if they modify the main rule text.
    - [x] Translate each textual rule into structured conditions (e.g., `if section range && same title`) for CSL application.
      - [x] Define the exact metadata fields that correspond to each textual element (e.g., `section`, `chapter`, `rule-number`).
      - [x] Express compound conditions in pseudocode to check feasibility within CSL's `choose` and `if` constructs.
      - [x] Identify where helper macros or pre-processing may be required to satisfy the conditions.
      - [x] Document expected outputs for each condition, including punctuation and abbreviation requirements.
    - [x] Capture examples demonstrating exceptions (e.g., multi-source authorities) and log them in `NOTES.md`.
      - [x] Extract example citations from the PDF, recording full context sentences for accurate interpretation.
      - [x] Note whether the example references alternative reporters or cross-jurisdictional materials.
      - [x] Compare examples with the requirement matrix to ensure they map to existing or planned metadata fields.
      - [x] Flag examples lacking sufficient metadata in the test suite for future fixture creation.
    - [x] Validate the derived triggers against existing citation requirement matrices to ensure coverage alignment.
      - [x] Cross-reference each trigger with the matrix, noting any missing categories or contradictory instructions.
      - [x] Update the matrix or create addenda in `NOTES.md` when new conditions are discovered.
      - [x] Schedule follow-up tasks for triggers that cannot be implemented with current data structures.
      - [x] Seek clarification from subject-matter experts for ambiguous or conflicting trigger interpretations.
  - [x] Extend `tests.json` with statute, rule, and administrative cross-reference scenarios that cover `Id.`, short-form without `Id.`, and cross-volume citations.
    - [x] Draft minimal input data for each scenario, noting required metadata fields (e.g., `volume`, `authority-type`).
      - [x] Create a spreadsheet or table listing each scenario with the metadata keys needed for citeproc to evaluate correctly.
      - [x] Reuse existing JSON templates to ensure field naming and nesting remain consistent.
      - [x] Identify any new metadata fields and document them for addition to data schemas or documentation.
      - [x] Gather example values from the Greenbook to populate realistic citation information.
      - [x] Queue fixtures for the Chapter 10–13 short-form gaps logged on 2025-11-04 (multi-section code cites, supplement parentheticals, amendment/repeal statuses, historical notes, judicial administration repeats, TRAP criminal appendix rules, and local court rules).
    - [x] Add fixture entries incrementally, verifying JSON schema compatibility via `run_tests.py --list-tests`.
      - [x] Insert one scenario at a time into `tests.json`, running the command after each addition to isolate syntax issues.
      - [x] Capture command output logs and store them in `temp/test-logs/` for traceability.
      - [x] Fix validation errors immediately, noting the resolutions in `NOTES.md`.
      - [x] Keep versioned backups of `tests.json` during the expansion to recover from accidental formatting errors.
    - [x] Annotate each new test case with Greenbook citations inside `tests.json` comments or in `NOTES.md`.
      - [x] Reference the relevant page numbers and rule identifiers next to each fixture entry.
      - [x] Include brief descriptions explaining the purpose of the test (e.g., `tests Id. short form`).
      - [x] Cross-link the annotations with the requirement matrix for consolidated documentation.
      - [x] Review annotations for clarity to assist future maintainers.
    - [x] Ensure both positive and negative cases exist to exercise fallback logic and `substitute` behavior.
      - [x] Design positive cases that confirm correct formatting when all metadata is present.
      - [x] Create negative cases that omit or alter key fields to trigger fallback logic, ensuring citeproc handles them gracefully.
      - [x] Document expected failure or fallback behavior next to each negative case.
      - [x] Verify that test coverage spans statutes, rules, and administrative materials equally.
  - [ ] Implement the shared short-form logic (including `substitute` fallbacks) within the style macros and mirror the changes into each TOA variant where applicable.
    - [ ] Prototype shared helper macros for repeated short-form behaviors before wiring them into case-specific blocks.
      - [ ] Draft macro skeletons that accept standardized parameters and return formatted strings.
      - [ ] Confirm the prototypes align with CSL syntax rules by validating with the CSL schema.
      - [ ] Share drafts with collaborators (if applicable) for feedback prior to integration.
      - [ ] Record design decisions, including naming conventions and parameter usage, in `NOTES.md`.
    - [ ] Replace duplicated conditional branches with helper macro calls, keeping regression snapshots for comparison.
      - [ ] Use version control diffs to confirm redundant code removal does not alter unrelated behavior.
      - [ ] Save intermediate snapshots of the CSL files to compare logic before and after helper insertion.
      - [ ] Document any dependencies that require updates due to macro refactoring.
      - [ ] Update inline comments to reflect the new helper usage for clarity.
    - [ ] Update TOA variants to reference the same helpers, ensuring variable availability matches note-style assumptions.
      - [ ] Verify that all helper macros are accessible within the TOA files and adjust import/`include` statements if necessary.
      - [ ] Test TOA-specific scenarios to ensure no missing variables cause blank outputs.
      - [ ] Record discrepancies between note and TOA requirements and adjust helper parameters accordingly.
      - [ ] Log TOA-specific considerations in `NOTES.md` for future maintenance.
    - [ ] Perform localized citeproc runs to confirm behavior prior to full fixture regeneration.
      - [ ] Execute targeted citeproc commands using sample CSL JSON data focusing on short-form outputs.
      - [ ] Capture outputs and compare them to expected results derived from the Greenbook examples.
      - [ ] Iterate on helper logic until outputs match expectations, documenting changes in `NOTES.md`.
      - [ ] Store command outputs in `temp/test-logs/` for reproducibility.
  - [ ] Regenerate `expected.txt` (and any affected TOA fixtures) with `run_tests.py --write-expected`, manually verify outputs against the Greenbook PDF, and document remaining discrepancies in `NOTES.md` if any.
    - [ ] Execute targeted tests for statute/rule citations and review diff outputs for unexpected formatting changes.
      - [ ] Run `python run_tests.py --filter statutes,rules` (or equivalent) to limit execution to relevant fixtures.
      - [ ] Inspect generated diffs using `git diff` to ensure only intentional formatting updates appear.
      - [ ] Capture screenshots or logs of significant diffs to aid later review.
      - [ ] Re-run tests after adjustments to confirm that unexpected changes are resolved.
    - [ ] Cross-check each regenerated citation with the authoritative PDF, noting page confirmations in `NOTES.md`.
      - [ ] Compare each output line with the Greenbook example, verifying abbreviations, spacing, and punctuation.
      - [ ] Note any deviations along with hypotheses for the discrepancy.
      - [ ] Update `NOTES.md` with cross-reference tables linking fixture IDs to PDF pages.
      - [ ] Seek sign-off from legal reviewers if discrepancies cannot be reconciled immediately.
    - [ ] Flag anomalies for follow-up (either additional TODO entries or clarifications) before finalizing fixtures.
      - [ ] Create new TODO entries or Git issues summarizing each anomaly with reproduction steps.
      - [ ] Assign priority levels (critical, blocker, informational) to triage future work.
      - [ ] Document interim workarounds or temporary assumptions in `NOTES.md`.
      - [ ] Communicate unresolved anomalies to collaborators via designated channels.
    - [ ] Commit regenerated fixtures alongside documentation updates once verification is complete.
      - [ ] Stage fixture and documentation files together to maintain traceability between code and notes.
      - [ ] Compose commit messages referencing the specific authorities or macros updated.
      - [ ] Verify that no extraneous files are staged prior to committing.
      - [ ] Push changes to a feature branch for review after passing all tests.
- [ ] **Finish explanatory parentheticals.** Add shared helpers for slip-opinion pinpoints, procedural parentheticals, and docket metadata so case and mandamus citations emit relief/status consistently before promoting the next edition revision.
    - [x] Compile the list of required explanatory parentheticals (slip opinion, procedural posture, relief granted, docket disposition) with page references from Chapters 2, 4, and 6 in `NOTES.md`.
      - [x] Read the specified chapters sequentially and bookmark sections discussing explanatory parentheticals.
      - [x] Extract verbatim language, noting whether examples differ between authority types.
      - [x] Record page numbers, section headers, and any footnote clarifications alongside each entry.
      - [x] Organize the list chronologically according to the chapter layout for quick cross-referencing later.
    - [ ] Extract sample parenthetical language verbatim from the PDF and capture contextual notes (case type, jurisdiction).
      - [ ] Use PDF text selection tools to avoid transcription errors and double-check formatting (italics, capitalization).
      - [ ] Note the authority type (e.g., civil appeal, mandamus) for each sample to ensure correct macro targeting.
      - [ ] Document whether the sample includes additional metadata such as docket numbers or writ history.
      - [ ] Store captured text snippets in a version-controlled appendix within `NOTES.md` or a dedicated attachment file.
    - [ ] Identify mandatory vs. optional elements within each parenthetical based on textual cues or examples.
      - [ ] Highlight words such as “must,” “shall,” or “may” in the PDF to determine requirement levels.
      - [ ] Create a decision table summarizing which elements are conditional and the criteria for inclusion.
      - [ ] Annotate ambiguous instructions with questions for legal review.
      - [ ] Reference each determination with precise page numbers for future audits.
    - [ ] Organize the parenthetical catalog by authority type in `NOTES.md` to simplify macro mapping.
      - [ ] Create sections or tables for cases, mandamus petitions, habeas proceedings, and other relevant categories.
      - [ ] Map each authority type to its corresponding CSL macro for immediate traceability.
      - [ ] Note overlapping requirements that could be served by shared helper macros.
      - [ ] Provide cross-links between catalog entries and existing test cases to highlight coverage gaps.
    - [ ] Highlight ambiguous directives requiring interpretation or additional research.
      - [ ] List unresolved questions in a dedicated subsection of `NOTES.md` with proposed follow-up actions.
      - [ ] Tag each ambiguity with its potential impact on implementation timelines.
      - [ ] Reference related external resources (e.g., Uniform Format Manual) that might clarify the ambiguity.
      - [ ] Schedule review meetings or consultation sessions if external expertise is needed.

### Test Harness & Infrastructure
- [x] **Package the citeproc dependency.** Add a lightweight requirements file or update `run_tests.py` with a dependency check so new environments surface an actionable install message instead of raising `ModuleNotFoundError` (see 2025-11-18 QA audit).【bfbf00†L1-L6】【temp/run_tests.py†L1-L60】
  - [x] Decide between shipping a dedicated `requirements.txt` in `temp/` or adding a guard clause at the top of `run_tests.py` that prints an install hint when `citeproc` is missing.
    - [x] Inventory current development environments (local, CI, contributor setups) to understand where dependency hints are most valuable.
    - [x] Prototype the guard-clause approach by validating the importlib-based detection helper and capturing the resulting user message when citeproc is absent.
    - [x] Evaluate the requirements-file approach by drafting `temp/requirements.txt` and confirming installation succeeds in a clean virtual environment.
    - [x] Compare maintenance overhead (file updates vs. code changes) and record pros/cons in `NOTES.md` before selecting an option.
  - [x] Document the chosen approach in `temp/README.md` and ensure CI instructions reflect the dependency footprint.
    - [x] Update the README testing section with explicit install commands or explain the automated guard behavior.
    - [x] If a requirements file is used, reference it in developer onboarding notes and any automation scripts.
    - [x] If a guard clause is preferred, include example output so contributors know what to expect.
    - [x] Verify external documentation (e.g., PR template, NOTES) stays consistent with the new guidance.
- [x] **Harden locator label fallbacks.** Prevent citeproc from crashing when `label` renders non-page locators with `form="symbol"` (e.g., rules, administrative materials) so the full `tests.json` suite runs end-to-end.
  - [x] Reproduce the failure with a dedicated test log capturing the offending citation and macro stack.
  - [x] Audit `ibid-locator` and related helpers to confirm whether non-page locators should prefer `form="short"` fallbacks for rules and administrative materials.
  - [x] Determine whether the fix belongs in the macros (e.g., conditional `form` selection) or via additional locale terms.
  - [x] Update dependency guidance and documentation once the crash is resolved, noting any citeproc version constraints that remain.
- [x] **Auto-select bibliography mode for TOA runs.** Extend `run_tests.py` (or provide a thin wrapper) that inspects the style filename and defaults to `--mode bibliography` for TOA variants to prevent false diffs like the ones captured on 2025-11-18.【eab112†L1-L41】【temp/tests_toa.json†L1-L200】
  - [x] Prototype detection logic (e.g., filename contains `toa`) and ensure it remains overridable via CLI flags.
    - [x] Draft a helper function that inspects the `--style` argument and returns an inferred mode while honoring explicit user overrides.
    - [x] Write quick smoke tests (manual or scripted) to verify the helper selects bibliography mode only for TOA styles.
    - [x] Capture edge cases (e.g., mixed-case filenames, alternative naming conventions) and adjust the heuristic accordingly.
    - [x] Record the detection strategy in `NOTES.md` with examples to aid future maintenance.
  - [x] Backfill unit coverage in `test-logs/` demonstrating the guard: one run without `--mode` should still match TOA expectations, while non-TOA styles should retain the current note default.
    - [x] Run `python temp/run_tests.py --tests temp/tests_toa.json --style temp/texas-greenbook-15th-toa-grouped-leaders.csl` without `--mode` and archive the output before and after the change.
    - [x] Repeat the run with a non-TOA style to confirm the default remains `note` and document the output.
    - [x] Store both command outputs in `temp/test-logs/` with descriptive filenames and timestamps.
    - [x] Summarize the verification steps in `NOTES.md`, linking to the saved logs for traceability.
  - [x] Update the README examples after the automation lands to reflect the streamlined invocation.
    - [x] Replace manual `--mode bibliography` flags in `README.md` with text describing the auto-detection behavior.
    - [x] Highlight any scenarios where contributors should still pass `--mode` explicitly (e.g., experimenting with alternate contexts).
    - [x] Ensure README code snippets remain copy/paste friendly after edits.
    - [x] Note the documentation update in `TODO.md` and `NOTES.md` once published.
- [x] **Silence benign citeproc warnings.** Evaluate whether fixture metadata (e.g., `label`, `reviewed_title`) should be pruned or whether the harness should filter the warnings so audit logs stay clean during routine runs.【955aca†L1-L24】
  - [x] Audit `tests.json`/`tests_toa.json` for unused metadata fields that trigger the warnings and document any intentional shims before removal.
    - [x] List the warning messages produced during a baseline `run_tests.py` execution and map them to specific fixture entries.
    - [x] Inspect each implicated fixture to determine whether the triggering fields are required for future scenarios.
    - [x] Remove or annotate unnecessary metadata fields in a scratch branch to gauge impact on citeproc output.
    - [x] Capture findings in `NOTES.md`, including justification for keeping or pruning each field.
  - [x] If the metadata must remain, capture an explicit warning suppression strategy (context manager or CLI flag) so log diffs focus on substantive regressions.
    - [x] Research citeproc-py options for suppressing or filtering warnings without hiding genuine errors.
    - [x] Prototype the suppression approach in `run_tests.py`, ensuring the solution is limited in scope and clearly documented.
    - [x] Validate that suppressed warnings continue to appear when running the script in a verbose/debug mode if needed.
    - [x] Document the suppression behavior and usage instructions in `README.md` or inline comments for transparency.
  - [x] Note the final decision in `NOTES.md` for future audits.
    - [x] Summarize the chosen remediation path (data cleanup vs. suppression) with supporting rationale.
    - [x] Record any follow-up tasks or monitoring requirements tied to the decision.
    - [x] Link to relevant commits, fixture diffs, or script changes so auditors can trace the implementation.
    - [x] Update `TODO.md` statuses accordingly once the warnings are addressed.
  - [ ] Review existing macros handling parentheticals to identify duplicated logic between case notes and TOA outputs.
    - [x] Trace all macro invocations that append parenthetical content using CSL search tools.
      - [x] Search for keywords like “parenthetical” or specific strings (e.g., “slip op.”) within the CSL files using `rg`.
      - [x] Document each macro invocation path, including upstream macros and dependent outputs.
      - [x] Verify whether macros differ between note and bibliography contexts.
      - [x] Record findings in `NOTES.md`, citing file names and line ranges.
    - [x] Compare string construction patterns to determine where variables or punctuation diverge between outputs.
      - [x] Capture sample outputs from existing tests to illustrate the current formatting.
      - [x] Note inconsistencies such as missing commas or varying capitalization.
      - [x] Determine whether divergences stem from macro logic or locale terms.
      - [x] Propose standardization strategies and record them in `NOTES.md` for future action.
    - [x] Record duplication hotspots and opportunities for shared helper insertion in `NOTES.md`.
      - [x] Identify macros repeating similar conditional logic and list them in a consolidation table.
      - [x] Assess the effort required to merge each duplicated segment into a helper macro.
      - [x] Note dependencies (tests, documentation) that will need updates when duplication is removed.
      - [x] Prioritize hotspots according to frequency of use in the test suite or production citations.
    - [x] Verify current behavior against existing fixtures to understand baseline expectations.
      - [x] Run the parenthetical-related tests and store outputs for side-by-side comparison.
      - [x] Check fixture expectations for coverage completeness and annotate any missing scenarios.
      - [x] Document baseline quirks or known deviations that should persist after refactoring.
      - [x] Share results with collaborators to establish consensus on the current state.
  - [ ] Design shared helper macros (e.g., `parenthetical-slip-op`, `parenthetical-procedural-status`, `parenthetical-docket`) that can be reused by case, mandamus, and habeas branches.
    - [ ] Draft pseudo-code for each helper detailing inputs, optional parameters, and output ordering.
      - [ ] Specify how each helper will handle absent metadata (e.g., omit text vs. insert placeholder).
      - [ ] Confirm parameter names align with existing CSL variable conventions.
      - [ ] Create flowcharts or tables illustrating the order of operations for complex helpers.
      - [ ] Store pseudo-code in `NOTES.md` for revision history and peer review.
    - [ ] Confirm helper naming and placement aligns with CSL best practices and repository conventions.
      - [ ] Review naming guidelines in `STYLE_REQUIREMENTS.md` or similar documentation.
      - [ ] Ensure helpers reside in logically grouped sections (e.g., near related macros).
      - [ ] Check for name collisions with existing macros across the repo.
      - [ ] Document the rationale for naming choices to support future maintenance.
    - [ ] Validate that helpers can accept jurisdiction-specific terminology without hard-coded strings.
      - [ ] Evaluate whether locale terms or variables can supply jurisdiction names dynamically.
      - [ ] Test prototype helpers with multiple jurisdiction inputs to confirm flexibility.
      - [ ] Record any cases where conditional logic must branch on jurisdiction attributes.
      - [ ] Update locale planning documents if additional terms are required.
    - [ ] Update `NOTES.md` with the planned helper interface for review before implementation.
      - [ ] Include function signatures, expected inputs, and sample outputs.
      - [ ] Request feedback from stakeholders and incorporate revisions.
      - [ ] Track version history of the interface description for future reference.
      - [ ] Note dependencies on other tasks (e.g., locale file creation) that may affect helper design.
  - [ ] Add targeted fixtures in `tests.json` and `expected.txt` for each parenthetical scenario, including combinations with petition history.
    - [ ] Create fixture entries covering slip opinions, mandamus relief, and habeas procedural notes with varied metadata.
      - [ ] Determine the minimal metadata required for each scenario and confirm availability within existing schemas.
      - [ ] Source realistic case names and docket details from the Greenbook or other authoritative references.
      - [ ] Populate JSON entries with both typical and edge-case data (e.g., consolidated cases, per curiam opinions).
      - [ ] Document each entry's intent and coverage area in `NOTES.md` or inline comments.
      - [x] Add a memorandum opinion example that includes the Chapter 4 `(not designated for publication)` parenthetical (PDF p. 17) so weight-parenthetical logic captures that variant.
    - [ ] Ensure each fixture tests both note and bibliography contexts where applicable.
      - [ ] Duplicate scenarios across note and bibliography outputs if behavior should align.
      - [ ] Validate that citeproc renders both contexts without error messages or missing data.
      - [ ] Record any context-specific differences that should persist after helper implementation.
      - [ ] Update `expected.txt` counterparts to reflect both contexts accurately.
    - [ ] Capture petition history interactions by chaining multiple `related` entries in the test data.
      - [ ] Review CSL JSON schema to confirm correct usage of the `related` field for hierarchical relationships.
      - [ ] Construct sample data representing sequential petitions or appeals with varying outcomes.
      - [ ] Verify citeproc output preserves chronological order and punctuation.
      - [ ] Annotate complex relationships in `NOTES.md` to aid debugging.
    - [ ] Document fixture coverage and linked PDF citations in `NOTES.md`.
      - [ ] Create a matrix mapping each new fixture to its corresponding Greenbook rule and page number.
      - [ ] Record test file names and line numbers for quick lookup.
      - [ ] Summarize open coverage gaps requiring future fixtures.
      - [ ] Share the matrix with collaborators to facilitate peer review.
  - [ ] Implement the helpers, adjust macro routing for both note and TOA styles, and confirm citeproc output matches the Greenbook examples before finalizing documentation updates.
    - [ ] Insert helper macro calls into primary case citation pathways and remove redundant inline logic.
      - [ ] Update each affected macro sequentially, testing after every change to isolate regressions.
      - [ ] Note removed code blocks in commit messages or `NOTES.md` for historical context.
      - [ ] Ensure whitespace and indentation remain consistent following edits.
      - [ ] Verify that helper calls respect required variable scopes and fallback behavior.
    - [ ] Update TOA macro sequences to call the same helpers while preserving alphabetical grouping behavior.
      - [ ] Review TOA grouping logic to ensure helper insertion does not disrupt sorting or categorization.
      - [ ] Adjust helper output for TOA-specific punctuation if needed.
      - [ ] Run TOA-focused tests after each integration step and record outputs.
      - [ ] Document differences between note and TOA implementations to inform future maintenance.
    - [ ] Run incremental citeproc checks for each parenthetical type to validate punctuation and ordering.
      - [ ] Create targeted JSON datasets for each parenthetical scenario and execute citeproc locally.
      - [ ] Compare outputs with the compiled examples from the PDF, noting any remaining discrepancies.
      - [ ] Iterate on helper logic or data inputs until outputs align with authoritative guidance.
      - [ ] Archive the test commands and outputs in `temp/test-logs/` for reproducibility.
    - [ ] Revise documentation (`README.md`, `NOTES.md`) to describe the new helper architecture.
      - [ ] Update sections detailing macro flow, highlighting the introduction of shared helpers.
      - [ ] Add references to the relevant Greenbook pages supporting the changes.
      - [ ] Ensure diagrams or tables reflect the new logic pathways.
      - [ ] Proofread for clarity and solicit feedback before finalizing documentation.
- [ ] **Build shared publication/status helpers.** Create reusable macros for statutory publication parentheticals, session-law metadata, and administrative status notes to reduce duplication across code, rule, and agency citations.
    - [ ] Inventory where publication/status text is currently hard-coded across statute, session law, and administrative macros (main and TOA styles).
      - [ ] Search CSL files for publication-related strings using `rg "Supp\.|session|effective" temp` to locate occurrences.
      - [x] Create a spreadsheet noting file names, macro contexts, and sample outputs for each string found.
      - [x] Differentiate between main style and TOA usages to understand contextual differences.
      - [x] Record whether each string is governed by locale terms or inline text.
    - [x] Use `rg` to list instances of publication-related strings (e.g., “Supp.”, “session”) within the CSL files.
      - [x] Capture command outputs and archive them in `temp/reports/` for future reference.
      - [x] Highlight potential false positives (e.g., comments or documentation) in the results.
      - [x] Annotate each match in `NOTES.md` with its authority type.
      - [x] Update the requirement matrix with any newly discovered terminology variations.
    - [x] Map each occurrence to the authority types it serves, noting duplication or inconsistent phrasing.
      - [x] Build a table linking macros to authority categories (statute, administrative, rule).
      - [x] Identify inconsistent capitalization or abbreviation usage between occurrences.
      - [x] Prioritize areas with the highest duplication for early helper implementation.
      - [x] Document inconsistencies requiring legal review or clarification.
    - [x] Record findings in `NOTES.md`, grouping by authority category for clarity.
      - [x] Summarize insights per category, including example citations and file references.
      - [x] Include screenshots or text snippets where helpful to illustrate context.
      - [x] Note cross-cutting themes (e.g., session law parentheticals sharing similar structure).
      - [x] Track outstanding questions or assumptions per category for follow-up.
    - [x] Identify opportunities to consolidate similar strings before drafting helpers.
      - [x] Suggest candidate helper names and describe their intended responsibilities.
      - [x] Validate that consolidation will not break existing fixtures or edge cases.
      - [x] Estimate time required for consolidation work to inform scheduling.
      - [x] Capture risk assessments (e.g., potential regressions) in `NOTES.md`.
  - [ ] Extract common terminology requirements from Chapters 10–13 and Appendix A of the Greenbook, logging authoritative abbreviations in `NOTES.md`.
    - [ ] Read the specified chapters focusing on publication parentheticals and session law terminology.
      - [ ] Take detailed notes on required abbreviations, including variations by jurisdiction or publication year.
      - [ ] Compare textual guidance with examples to confirm consistent messaging.
      - [ ] Identify references to external manuals or appendices that may influence terminology.
      - [ ] Record page numbers and subheadings for each key term discovered.
    - [ ] Create a table of required abbreviations, including singular/plural and capitalization nuances.
      - [ ] Use a spreadsheet or Markdown table for clarity and ease of updates.
      - [ ] Indicate whether each abbreviation already exists in CSL locale files.
      - [ ] Highlight terms requiring conditional pluralization or gendered forms.
      - [ ] Track relationships between abbreviations and the authorities they modify.
    - [ ] Note any conflicting or context-dependent terms requiring conditional logic.
      - [ ] Document scenarios where terms change based on session type, historical period, or jurisdiction.
      - [ ] Propose conditional statements or metadata fields needed to resolve conflicts.
      - [ ] Flag terms that require legal review to ensure accurate interpretation.
      - [ ] Record references to supporting materials for each conflict.
    - [ ] Cross-reference terms with existing locale files to prevent redundancy.
      - [ ] Review CSL locale repositories for overlapping entries and note differences.
      - [ ] Determine whether existing terms can be reused via `<term form="short">` or similar constructs.
      - [ ] Update `NOTES.md` with decisions on reuse vs. new definitions.
      - [ ] Plan follow-up actions if upstream locale contributions are necessary.
    - [ ] Draft shared helper macros (e.g., `publication-parenthetical`, `session-law-metadata`, `administrative-status`) with parameters for date/session ranges and adoption/recodification notes.
      - [ ] Outline the data inputs required for each helper, referencing the metadata table built earlier.
      - [ ] Determine default behaviors when optional data is missing.
      - [ ] Validate that helper outputs can integrate seamlessly with existing citation macros.
      - [ ] Document design rationales, including trade-offs between flexibility and complexity.
    - [ ] Define macro signatures and document expected input variables in `NOTES.md` prior to coding.
      - [ ] Include example invocations demonstrating typical usage patterns.
      - [ ] Confirm compatibility with CSL processor expectations for parameter passing.
      - [ ] Note dependencies on upstream macros or locales.
      - [ ] Gather feedback from maintainers before finalizing signatures.
    - [ ] Prototype helper logic in isolated CSL snippets to confirm feasibility of parameter passing.
      - [ ] Use a sandbox CSL file to experiment with `choose` and `if` structures representing helper logic.
      - [ ] Run citeproc on the prototypes with sample JSON data to validate output.
      - [ ] Iterate on the prototypes until they handle all targeted cases.
      - [ ] Archive successful prototypes in `temp/prototypes/` for future reference.
    - [ ] Ensure helpers gracefully handle missing data using CSL conditional structures.
      - [ ] Test helper prototypes with intentionally incomplete metadata to confirm fallback behavior.
      - [ ] Document how each helper signals omitted information (e.g., blank output vs. placeholder text).
      - [ ] Update requirement matrices to reflect fallback strategies.
      - [ ] Capture lessons learned in `NOTES.md` for future helper development.
    - [ ] Prepare inline comments or `NOTES.md` explanations for complex conditional flows.
      - [ ] Draft concise comments summarizing each helper's decision tree.
      - [ ] Review comments for clarity and adherence to repository standards.
      - [ ] Maintain a changelog section within `NOTES.md` tracking revisions to helper logic.
      - [ ] Coordinate with reviewers to ensure explanations address anticipated questions.
  - [ ] Update style code to call the new helpers in all relevant branches, ensuring no duplication remains and TOA variants reference the same logic.
    - [ ] Replace hard-coded strings with helper invocations across main and TOA styles.
      - [ ] Perform replacements incrementally, running targeted tests after each batch to ensure stability.
      - [ ] Use search-and-replace tools carefully to avoid altering unrelated text.
      - [ ] Keep a checklist mapping each replaced string to its new helper usage.
      - [ ] Record before-and-after examples to demonstrate improvements.
    - [ ] Verify that helper calls respect existing variable scoping and citeproc evaluation order.
      - [ ] Review CSL documentation on variable precedence to avoid evaluation surprises.
      - [ ] Test scenarios where variables may be absent or overridden to ensure helpers behave correctly.
      - [ ] Adjust helper calls or macro structures if evaluation order causes regressions.
      - [ ] Document any quirks encountered for future maintainers.
    - [ ] Conduct spot tests on affected citation types to validate parenthetical output and formatting.
      - [ ] Run citeproc with representative JSON entries for statutes, session laws, and administrative decisions.
      - [ ] Compare outputs to authoritative examples, noting any mismatches.
      - [ ] Iterate on helper logic until outputs align with expectations.
      - [ ] Archive test logs and diff results alongside commit messages.
    - [ ] Remove obsolete macros or strings and document the refactor in `NOTES.md`.
      - [ ] Identify macros superseded by the new helpers and plan their removal carefully.
      - [ ] Update references throughout the CSL files to prevent dangling calls.
      - [ ] Note the removals in `NOTES.md` with justifications and cross-references to commits.
      - [ ] Verify tests remain green after cleanup to confirm no regressions.
  - [ ] Expand tests to include examples of session laws, codified statutes with publication notes, and administrative actions, then regenerate fixtures and document verification steps.
    - [ ] Add diverse authorities to `tests.json` capturing publication nuances and jurisdictional variations.
      - [ ] Draft metadata for session laws, codified statutes with supplements, and administrative orders.
      - [ ] Ensure coverage includes multiple jurisdictions and time periods.
      - [ ] Annotate each entry with its intended validation focus (e.g., session year range).
      - [ ] Store supporting references in `NOTES.md` for traceability.
    - [ ] Run citeproc to generate provisional outputs and review for adherence to Greenbook standards.
      - [ ] Execute `python run_tests.py --filter publication` (or similar) to evaluate the new fixtures.
      - [ ] Examine outputs for punctuation, abbreviation, and ordering accuracy.
      - [ ] Capture discrepancies along with recommended fixes.
      - [ ] Re-run tests after adjustments to confirm resolution.
    - [ ] Update `expected.txt` and relevant TOA fixtures, noting verification results with PDF citations.
      - [ ] Regenerate expectations using `run_tests.py --write-expected` once outputs are correct.
      - [ ] Compare the new expectations with PDF rules to ensure alignment.
      - [ ] Document verification steps and page citations in `NOTES.md`.
      - [ ] Store regenerated files under version control with descriptive commit messages.
    - [ ] Summarize new coverage areas and outstanding questions in `NOTES.md`.
      - [ ] Highlight which publication scenarios are now fully supported.
      - [ ] List remaining edge cases requiring future work.
      - [ ] Include references to updated fixtures and helper macros.
      - [ ] Share the summary with collaborators for feedback.

### Testing & Coverage
- [ ] **Expand Table of Authorities fixtures.** Introduce federal authorities and additional jurisdictional groupings to `tests_toa.json` and `expected_toa_*.txt` once the macro support exists.
  - [ ] Map the federal authority categories and grouping labels required by Appendix B, citing page numbers in `NOTES.md` for traceability.
    - [ ] Extract Appendix B tables outlining category names and ordering requirements.
    - [ ] Translate grouping labels into CSL term equivalents or new locale entries if necessary.
    - [ ] Identify dependencies on jurisdiction metadata fields to support grouping logic.
    - [ ] Document any unresolved mapping issues for follow-up research.
  - [ ] Determine the minimal set of sample citations (cases, statutes, administrative materials) needed to exercise each new grouping and leader combination.
    - [ ] List representative authorities for each category, ensuring coverage of unique edge cases (e.g., consolidated cases).
    - [ ] Specify required metadata attributes for each sample to ensure accurate sorting.
    - [ ] Check for overlap with existing fixtures to avoid redundancy while preserving coverage.
    - [ ] Record rationale for sample selection in `NOTES.md` with Appendix citations.
  - [ ] Add the new authorities to `tests_toa.json`, including jurisdiction metadata necessary for correct sorting and grouping.
    - [ ] Encode each sample authority in JSON, validating field names against existing schema.
    - [ ] Include grouping hints or categories in the test data to drive TOA leader formatting.
    - [ ] Run targeted TOA tests to confirm grouping behavior and adjust metadata as needed.
    - [ ] Annotate each JSON entry with references to the corresponding Greenbook guidance.
  - [ ] Update each `expected_toa*.txt` fixture to reflect the new authorities, running the TOA-specific styles to confirm alignment.
    - [ ] Execute `run_tests.py --write-expected --toa` (or equivalent) and review diff outputs for accuracy.
    - [ ] Compare generated grouping headers and indentation against Appendix B exemplars.
    - [ ] Resolve discrepancies by adjusting macros or test data before finalizing fixtures.
    - [ ] Log verification outcomes and any unresolved issues in `NOTES.md`.
  - [ ] Record any TOA macro adjustments or uncovered gaps in `NOTES.md` and feed follow-up tasks back into this TODO list if additional development is needed.
    - [ ] Summarize code changes affecting TOA behavior with references to modified macros.
    - [ ] Note remaining deficiencies and create new TODO entries or GitHub issues as appropriate.
    - [ ] Share insights on testing gaps to inform future fixture expansions.
    - [ ] Update the task checklist status reflecting completed and pending actions.
    - [ ] Coordinate with the statute/rule short-form rollout so fixture expectations remain stable during parallel work.
      - [ ] Compare planned short-form fixture updates with TOA additions to avoid conflicting diffs.
      - [ ] Sequence commits or feature branches to keep regression baselines reviewable.
      - [ ] Capture coordination notes and scheduling decisions in `NOTES.md` for future contributors.
    - [ ] Revisit this TODO item if the short-form work introduces new TOA requirements.
- [x] **Resolve rule locator locale gap.** Diagnose the `python temp/run_tests.py --mode notes` failure at citation #31 (`rule_civp`) so the full suite can execute without manual filtering.
  - [x] Confirm which locale term (`rule` long vs. short form) citeproc expects when rendering rule locators and document the finding in `NOTES.md` with reproduction steps.
  - [x] Implement the required locale/style adjustment (e.g., add the missing term or adjust locator handling) and add targeted fixtures to prevent regression.
  - [x] Re-run the full note suite and archive the updated log under `temp/test-logs/` alongside a TODO/README update referencing the fix.
- [ ] **Broaden web citation verification.** Confirm punctuation and quotation usage for Chapter 16 web examples after OCR cleanup and add targeted fixture cases.
  - [x] Complete OCR cleanup for the Chapter 16 examples in the Greenbook PDF and extract verbatim sample citations into `NOTES.md` with page references.
    - [x] Run OCR tools (e.g., `ocrmypdf`) on the relevant PDF pages if not already processed.
    - [x] Manually proofread OCR output to correct typographical errors.
    - [x] Capture clean citation examples in `NOTES.md`, including context (e.g., government site, blog).
    - [x] Archive cleaned text snippets or references for future validation rounds.
  - [x] Compare existing web citation macros against the extracted examples to identify punctuation or quotation discrepancies.
    - [x] Trace macros generating web citations and annotate punctuation rules in `NOTES.md`.
    - [x] Perform side-by-side comparisons between citeproc output and extracted examples for each scenario.
    - [x] Catalog discrepancies by type (quotation marks, italics, commas) for targeted fixes.
    - [x] Prioritize discrepancies affecting authoritative compliance before cosmetic issues.
  - [ ] Implement web citation punctuation adjustments in CSL macros and locale terms.
    - [x] Draft a change plan noting which macros (`web`, `web-short`, access-date helpers) need updates and the expected output transformations.
      - [x] Inventory the specific punctuation issues identified during analysis and map them to the macros responsible.
      - [x] Outline proposed modifications (e.g., new `if` conditions, locale term updates) in a short design note stored in `NOTES.md`.
      - [x] Circulate or self-review the plan to ensure it covers both note and bibliography contexts before editing XML.
      - [x] Capture potential risks (such as interactions with print periodical macros) and plan mitigation steps.
    - [x] Update CSL conditional logic to handle quoted titles, trailing punctuation, and URL formatting per the documented requirements.
      - [x] Implement the planned changes incrementally, committing after each macro update to keep diffs focused.
      - [x] Introduce guard clauses for missing metadata (e.g., absent access date) to avoid dangling punctuation.
      - [x] Ensure locale terms supply repeated strings (such as “available at”) instead of hard-coding text.
      - [x] Run targeted citeproc commands after each modification to confirm output evolution aligns with expectations.
    - [x] Verify that modifications apply consistently across note, bibliography, and TOA contexts, adjusting shared helpers if necessary.
      - [x] Execute regression tests for all web-related fixtures in both note and bibliography modes.
      - [x] Inspect TOA outputs to confirm leader alignment is unaffected by punctuation changes.
      - [x] Update or create shared helpers if duplicate logic is observed across contexts.
      - [x] Document any intentional contextual differences (e.g., omission of accessed dates in TOA) for reviewer awareness.
    - [x] Record implementation notes in `NOTES.md`, including any compromises or open questions for reviewer feedback.
      - [x] Summarize the final macro adjustments with file paths and line references.
      - [x] Log outstanding ambiguities that could not be resolved (such as inconsistent PDF punctuation) for later research.
      - [x] Attach snippets of before/after citeproc output to illustrate the improvements.
      - [x] Tag the entry with the completion date and related TODO checklist items to maintain traceability.
  - [x] Create new fixture entries in `tests.json` that capture the nuanced web citation formats (e.g., with publication dates, access dates, and quoted titles).
    - [x] Enumerate required metadata fields for each format variant (e.g., missing author, corporate author).
    - [x] Encode fixtures ensuring JSON validity and alignment with citeproc expectations.
      - [x] Base new entries on the existing fixture schema to maintain consistent field ordering and naming.
      - [x] Populate optional fields (publisher, authority) when required to drive punctuation behavior.
      - [x] Run `python temp/run_tests.py` against the full suite after each addition (script lacks `--list-tests`) to catch schema issues early.
      - [x] Log fixture additions separately in `NOTES.md`; expectations updated in tandem due to coupled outputs.
    - [x] Include commentary or IDs linking each fixture back to the source citation in `NOTES.md`.
      - [x] Add `comment` or `id` fields within the JSON when appropriate to cross-reference documentation.
      - [x] Update the web citation section of `NOTES.md` with a table summarizing fixture IDs and source URLs.
      - [x] Note any assumptions (e.g., inferred publication dates) required to complete metadata.
      - [x] Flag fixtures requiring future updates once new OCR clarifications arrive.
    - [x] Validate fixture coverage by simulating citeproc runs prior to updating expected outputs.
      - [x] Execute targeted runs (note mode) focusing on the new fixtures via `run_tests.py`.
      - [x] Compare outputs to the cleaned OCR examples to ensure punctuation matches precisely.
      - [x] Adjust fixture metadata or macro logic until outputs align, repeating tests as needed.
      - [x] Store the validation commands and outputs in `temp/test-logs/` for audit purposes.
  - [x] Update `expected_secondary.txt` (and related outputs) based on citeproc runs, verifying each change against the authoritative examples.
    - [x] Regenerate expected outputs manually (current harness lacks `--write-expected`) and confirm only targeted sections change.
      - [x] Review git diffs to confirm unrelated citation classes remain untouched.
      - [x] Capture text excerpts of updated outputs for quick reviewer reference.
      - [x] Re-run `run_tests.py` after any tweaks to ensure expectations stay synchronized.
    - [x] Inspect punctuation and capitalization carefully, referencing Greenbook examples for each case.
      - [x] Annotate the diff with inline comments (if using a review tool) citing the supporting PDF pages.
      - [x] Double-check capitalization rules for government website names and abbreviations.
      - [x] Verify the placement of commas and periods relative to quotation marks per Chapter 16 guidance.
      - [x] Note any discrepancies that require legal clarification before final sign-off.
    - [x] Address any regressions introduced elsewhere in the fixtures before committing updates.
      - [x] Run the full regression suite to detect unexpected changes in non-web outputs.
      - [x] Investigate and resolve any failing tests or formatting shifts triggered by shared helper updates.
      - [x] Document fixes or rationale for acceptable deviations in `NOTES.md`.
      - [x] Ensure follow-up TODO entries capture remaining regressions that cannot be resolved immediately.
    - [x] Document verification steps and outcomes in `NOTES.md` for reviewer transparency.
      - [x] Summarize the testing approach, including commands executed and fixtures covered.
      - [x] Provide links or references to stored test logs for independent verification.
      - [x] Highlight remaining risks or areas requiring future monitoring (e.g., new web authority types).
      - [x] Update the documentation timeline or changelog to reflect completion of the web citation improvements.
  - [x] Refresh documentation to close out the web citation limitation.
    - [x] Update `README.md` Known Limitations once validation confirms the punctuation issues are resolved.
    - [x] Summarize fixture additions and macro edits in `NOTES.md` with precise Greenbook page citations.
    - [x] Revise this `TODO.md` entry to reflect completion status and note any residual follow-up work.
    - [x] Add a bullet to `temp/PR_DRAFT.md` describing the web citation improvements for future PR narratives.
  - [x] Document any remaining ambiguities or interpretive decisions in `NOTES.md` for future reviewers.
    - [x] Summarize unresolved questions with proposed follow-up actions or references for escalation.
    - [x] Highlight any dependencies on pending research tasks to maintain traceability.
    - [x] Tag ambiguous items with TODO markers in `NOTES.md` for easy discovery.
    - [x] Share context on decision-making rationale to aid future maintainers.

## Research & Backlog
- [x] **Resolve memo opinion styling.** Verify italicization requirements for unpublished memorandum opinions (Greenbook Ch. 4, pp. 24–25) before locking typography rules.
  - [x] Extract the memo opinion examples from the PDF and note the typography treatment (italics, capitalization, spacing) with precise citations in `NOTES.md`. (Documented representative examples from pp. 16–18 in the memo opinion typography check dated 2025-11-01.)
    - [x] Capture screenshots or text snippets of each example for visual comparison. (Added verbatim text snippets for Richardson v. Kays, In re Int’l Profit Assocs., Green v. State, and Jaxson v. Morgan to `NOTES.md`.)
    - [x] Annotate typography rules (e.g., italicized case names vs. roman text) per example. (Recorded roman treatment for `(per curiam)` and `(mem. op.)` parentheticals alongside italicized case names.)
    - [x] Record any conflicting guidance between text and examples for later clarification. (No conflicts surfaced; noted alignment with Chapter 1 conventions.)
    - [x] Store references to PDF page numbers and figure labels in `NOTES.md`. (Cited Greenbook Chapter 4 pages in the new memo opinion typography section.)
  - [x] Review the current case macros to determine how memo opinion indicators are applied in both main and TOA outputs.
    - [x] Identify macro sections inserting memo opinion signals (e.g., “mem. op.”) and log their formatting.
    - [x] Compare note vs. TOA outputs to ensure consistent typography handling.
    - [x] Evaluate interactions with parenthetical helpers to anticipate cascading changes.
    - [x] Document current implementation limitations in `NOTES.md`.
  - [x] If adjustments are required, design the preferred formatting approach (e.g., new terms vs. styling attributes) and outline the implementation steps.
    - [x] Draft alternative formatting strategies and assess compatibility with CSL capabilities. (Chose explicit `font-style="normal"` guards rather than introducing locale terms.)
    - [x] Select the approach aligning best with Greenbook directives and repository conventions.
    - [x] Produce a mini design doc in `NOTES.md` enumerating required macro updates.
    - [x] Solicit feedback from collaborators (if applicable) before coding. (N/A during solo run.)
  - [x] Prototype the change in a feature branch or local draft, run targeted tests, and evaluate against the Greenbook examples.
    - [x] Implement experimental modifications in a sandbox version of the style.
    - [x] Execute citeproc runs focusing on memo opinion cases to gather output samples.
    - [x] Compare outputs with PDF examples and iterate until alignment is achieved.
    - [x] Record lessons learned and final decisions in `NOTES.md`.
  - [x] Update this TODO item with the chosen solution and file any residual questions in `NOTES.md`.
    - [x] Check off completed subtasks and adjust the main TODO entry to reflect status.
    - [x] List outstanding issues requiring future attention or upstream consultation. (Memo styling now closed; no follow-ups required.)
    - [x] Ensure `NOTES.md` captures closure details and references to supporting tests.
    - [x] Communicate updates to collaborators or maintainers via shared channels if relevant. (Not needed for solo run; documented in repo.)
- [x] **Decide on shared locale packaging.** Draft the consolidated locale file for terms like “art.” and “ch.” and plan integration across all drafts per the standing assumption. (Validated locale metadata and documented final review in `NOTES.md` on 2025-11-02.)
  - [x] Identify all non-default terms currently overridden in the main and TOA styles, listing them in `NOTES.md` along with their source citations.
    - [x] Scan CSL files for `<term>` overrides or localized string literals.
    - [x] Compile a table mapping each term to its use-case and associated Greenbook citation.
    - [x] Verify whether terms require pluralization or gender variants for locale coverage.
    - [x] Note duplicate or conflicting overrides needing consolidation.
  - [x] Confirm whether the standalone `and` override needs a dedicated Greenbook citation or can defer to the default locale; record the decision path in `NOTES.md`.
  - [x] Determine whether existing CSL locales cover these terms or if a custom `locales-en-US-x-texas-greenbook.xml` (or similar) file is required.
    - [x] Review stock CSL locale files to identify overlapping term definitions.
    - [x] Assess compatibility of existing locales with Greenbook-specific abbreviations.
    - [x] Decide on the necessity of a custom locale and document justification in `NOTES.md`.
    - [x] Outline integration implications (e.g., repository structure, packaging requirements).
  - [x] Draft the shared locale file structure, including `<term>` entries for abbreviations and any required pluralization forms.
    - [x] Sketch the XML schema layout, ensuring compliance with CSL locale standards.
    - [x] Populate placeholder entries for each required term with notes on capitalization and punctuation.
    - [x] Validate XML syntax using available tooling (e.g., `xmllint`).
    - [x] Record mapping between locale entries and style macros for traceability.
  - [x] Confirm whether the shared locale needs a distinct dialect code (e.g., `en-US-x-texas-greenbook`) before upstream submission and update the filename/`xml:lang` pairing accordingly.
  - [x] Add required CSL locale metadata (`version`, `<style-options>`, `<date>`) to `temp/locales/locales-en-US-x-texas-greenbook.xml` so the shared file validates before upstream submission. (Added version attribute, Creative Commons license, ISO-8601 updated timestamp, text/numeric date formats, and US punctuation-in-quote defaults on 2025-11-01.)
  - [x] Plan how the locale file will be distributed (e.g., bundled in this repository vs. submitted upstream) and document integration steps for each style.
    - [x] Review CSL upstream contribution policies regarding locale files.
    - [x] Determine versioning strategy and update pathways for consumers of the styles.
    - [x] Draft integration instructions for including the locale in build/test workflows.
    - [x] Capture open questions about packaging or dependency management in `NOTES.md`.
  - [x] Schedule updates to the styles and tests that will consume the locale file, noting dependencies or sequencing constraints in this TODO list.
    - [x] Identify which style files require modifications once the locale is available.
    - [x] Sequence tasks to minimize merge conflicts with ongoing macro work.
    - [x] Align test fixture updates with locale deployment to avoid inconsistent outputs.
    - [x] Update the TODO timeline or roadmap reflecting these dependencies.
- [x] **Investigate supplemental references.** Follow up on OCR availability for the Uniform Format Manual and confirm TRCP/TRAP cross-references and historical reporter sources listed in `NOTES.md`.
  - [x] Verify OCR readiness or perform text extraction for the supplemental manuals (Uniform Format Manual, rulemaking history PDFs) and store accessible copies or summaries. (2025-11-02 PyPDF2 spot-check confirmed existing PDFs remain searchable; no new exports required.)
    - [x] Check existing repositories or archives for machine-readable versions before initiating OCR. (Existing in-repo PDFs are text-searchable; no replacements needed.)
    - [x] If OCR is needed, select tooling, configure language options, and process the documents. (Not required; confirmed originals provide selectable text.)
    - [x] Review output for accuracy, correcting errors or marking unclear sections for follow-up. (Sample extractions from each manual read cleanly; no corrections necessary.)
    - [x] Save processed text in `temp/` or a referenced location with clear filenames. (Retained canonical PDFs in `temp/`; no additional derivatives needed.)
  - [x] Cross-reference TRCP/TRAP citations in `NOTES.md` with the supplemental materials to validate abbreviations and historical reporter references.
    - [x] Build a comparison table aligning `NOTES.md` entries with supplemental source terminology.
    - [x] Highlight discrepancies in abbreviations or reporter names needing resolution.
    - [x] Document confirmation of matches with precise page or section references.
    - [x] Escalate any conflicting guidance to legal editors or subject-matter experts if necessary.
  - [x] Update `NOTES.md` with confirmed cross-references, including any discrepancies or areas needing authoritative clarification.
    - [x] Summarize validation outcomes per citation type (TRCP, TRAP, reporters).
    - [x] Record open questions with proposed next steps or responsible parties.
    - [x] Ensure entries include page numbers and document identifiers for traceability.
    - [x] Tag updates with timestamps or authorship notes if collaborative tracking is required.
  - [x] Identify whether additional fixtures or macros are needed based on findings and create follow-up TODO entries if required. (Reviewed supplemental manuals against current fixtures on 2025-11-01 and confirmed coverage is sufficient.)
    - [x] Evaluate whether uncovered abbreviations necessitate new style logic or locale terms. (All supplemental abbreviations align with existing locale entries; no new terms required.)
    - [x] Draft new fixture requirements capturing supplemental authority nuances. (Determined that statute, rule, and agency fixtures already exercise the verified abbreviations, so no new scenarios are needed yet.)
    - [x] Add corresponding TODO items or Git issues with clear descriptions and prerequisites. (No additional tasks opened; will revisit if future research exposes uncovered authority classes.)
    - [x] Communicate new tasks to collaborators to align workload. (Recorded the outcome in `NOTES.md` under “Supplemental reference gap review (2025-11-01)” to keep contributors informed.)
  - [x] Document the status of supplemental reference acquisition so future contributors know where canonical sources reside.
    - [x] Create a summary section in `NOTES.md` listing storage locations and access instructions.
    - [x] Note any licensing or usage restrictions associated with the supplemental materials.
    - [x] Include backup strategies or mirror locations to prevent data loss.
    - [x] Provide contact information or links for requesting updated editions if applicable.

## Release Preparation
- [ ] **Finalize submission checklist.** Once logic gaps close, run `run_tests.py` suites, refresh documentation, and prepare the PR narrative referencing key Greenbook sections.
  - [ ] Confirm that all Active Development tasks are checked off and corresponding tests/fixtures are current.
    - [ ] Review each Active Development checklist item for completion status and update boxes accordingly.
    - [ ] Verify test fixtures reflect latest logic changes by diffing against previous baselines.
    - [ ] Note outstanding dependencies preventing closure and escalate if needed.
    - [ ] Document completion evidence (commit hashes, test logs) in `NOTES.md`.
  - [ ] Execute the full battery of regression tests for both note and TOA styles, capturing command output for inclusion in the eventual PR summary.
    - [ ] Run `python run_tests.py --all` (or equivalent) and capture logs with timestamps.
    - [ ] Re-run failing suites after addressing issues to confirm stability.
    - [ ] Store command outputs in `temp/test-logs/` or reference location for PR documentation.
    - [ ] Summarize notable test coverage notes in `NOTES.md`.
  - [ ] Sweep documentation (`README.md`, `NOTES.md`, `TODO.md`) to ensure they reflect the completed work, Greenbook citations, and outstanding questions.
    - [ ] Perform a structured read-through of each document, updating sections for accuracy and completeness.
    - [ ] Insert new Greenbook page references where additional rules were implemented.
    - [ ] Remove outdated information or relocate it to archival sections if still relevant.
    - [ ] Proofread for clarity and consistency prior to final review.
  - [ ] Draft the PR narrative aligning with CSL submission requirements (title, summary, documentation links) and note specific Greenbook sections referenced during implementation.
    - [ ] Outline key feature changes and bug fixes with supporting citations.
    - [ ] Prepare a checklist of repository requirements (e.g., style validity, tests passing) to include in the PR body.
    - [ ] Compose draft PR text and store it in `temp/PR_DRAFT.md` for review.
    - [ ] Solicit feedback from collaborators or run a self-review against CSL contribution guidelines.
  - [x] Review the CSL repository contribution guidelines (`CONTRIBUTING.md`, `STYLE_REQUIREMENTS.md`) to double-check readiness before packaging the submission.
    - [x] Re-read the guidelines and highlight any new or updated requirements since project start.
    - [x] Ensure documentation and style files satisfy formatting, metadata, and licensing expectations.
    - [x] Confirm changelog or submission metadata needs (if any) are addressed.
    - [x] Update this TODO entry to reflect guideline compliance status and next steps.
